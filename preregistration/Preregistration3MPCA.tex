\documentclass[]{article}
    \usepackage{lmodern}
    \usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
  \else % if luatex or xelatex
\ifxetex
\usepackage{mathspec}
\usepackage{xltxtra,xunicode}
\else
  \usepackage{fontspec}
\fi
\defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
\newcommand{\euro}{â‚¬}
        \fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
  \usepackage{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
  \usepackage[left=2.5in,bottom=1.25in,top=1.25in,right=1in]{geometry}
  \ifxetex
\usepackage[setpagesize=false, % page size defined by xetex
            unicode=false, % unicode breaks when used with xetex
            xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
bookmarks=true,
pdfauthor={},
pdftitle={Migration Experience Trajectories: A Three Mode Principle Component Analysis},
colorlinks=true,
citecolor=blue,
urlcolor=blue,
linkcolor=magenta,
pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{apalike}
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
\setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}

% Customization for cos_prereg
\usepackage{longtable,booktabs,threeparttable,tabularx}
\linespread{1.5}
\newcounter{question}
\setcounter{question}{0}

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

\def\changemargin#1#2{\list{}{\rightmargin#2\leftmargin#1}\item[]}
\let\endchangemargin=\endlist

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
\posttitle{
\begin{center}\large#1\end{center}
}
}

\setlength{\droptitle}{-2em}
\title{Migration Experience Trajectories: A Three Mode Principle
Component Analysis}
\pretitle{\begin{changemargin}{-8pc}{0pc} \centering\large Preregistration\\ \Huge}
\posttitle{\end{changemargin}}
  \author{
          Jannis Kreienkamp\textsuperscript{1},
          Kai Epstude\textsuperscript{1},
          Rei Monden\textsuperscript{2},
          Maximilian Agostini\textsuperscript{1},
          Peter de Jonge\textsuperscript{1},
          Laura F.
Bringmann\textsuperscript{1}          \\ \vspace{0.5cm}
              \textsuperscript{1} University of Groningen, Department of
Psychology\\
              \textsuperscript{2} Hiroshima University, Graduate School
of Advanced Science and Engineering      }

  \def\affdep{{"", "", "", "", "", ""}}%
  \def\affcity{{"", "", "", "", "", ""}}%
  \preauthor{\begin{changemargin}{-8pc}{0pc} \centering\large}
  \postauthor{\end{changemargin}}
\date{20. May 2022}
\predate{\begin{changemargin}{-8pc}{0pc} \centering\large\emph}
\postdate{\end{changemargin}}
\usepackage{fancyhdr}
\pagestyle{fancy}
\setlength{\headheight}{14.0pt}
\renewcommand{\headrulewidth}{0pt}
\lhead{}
\rhead{\large\textsc{\MakeLowercase{Preregistration: Migration
Experience Trajectories}}}

\usepackage{amsmath}
\usepackage{nccmath}
\usepackage{LatexPackage/trackchanges}
\usepackage[usenames,dvipsnames]{xcolor}
\addeditor{Jannis}


% Title settings
\usepackage{titlesec}
\titleformat{\section}[display]{\bfseries\Large}{\thesection}{}{}[]
\titlespacing{\section}{0pc}{*3}{*1.5}
\titleformat{\subsection}[leftmargin]{\titlerule\bfseries\filleft}{\thesubsection}{.5em}{}
\titlespacing{\subsection}{8pc}{5ex plus .1ex minus .2ex}{1.5pc}


% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\begin{document}
\maketitle
\vspace{2pc}


\newcommand\Question[2]{%
   \leavevmode\par
   \stepcounter{question}
   \noindent
   \textbf{\thequestion. #1}. #2\par}

\newcommand\Answer[1]{%
    \noindent
    \textit{Registered response}: #1\par}

\newlength{\mylength}
\setlength{\fboxsep}{15pt}
\setlength{\mylength}{\linewidth}
\addtolength{\mylength}{-2\fboxsep}
\addtolength{\mylength}{-2\fboxrule}
\definecolor{editPurple}{RGB}{84, 28, 117}

\hypertarget{study-information}{%
\section{Study Information}\label{study-information}}

\hypertarget{title}{%
\subsection{Title}\label{title}}

Migration Experience Trajectories: A Three Mode Principle Component
Analysis

\hypertarget{description}{%
\subsection{Description}\label{description}}

Recent reviews have called for more comprehensive assessment of human
experiences and for more longitudinal real-life data, within the
psychological sciences more broadly and in migration research in
particular
\citep[e.g.,][]{Kreienkamp2022d, MacInnis2015, McKeown2017, Pettigrew2011, Ward2019}.
However, while generally speaking analytical methods for such, more
complex, data have become more readily available
\citep[e.g.,][]{ODonnell2021}, it remains unclear how we should identify
key developmental patterns --- especially across multiple variables at
the same time.

In essence, the novel extensive longitudinal datasets come with new
forms of heterogeneity, where we have to consider differences between
people, over time, and across variables. Yet, past analytical advances
have almost exclusively pushed for top-down inferential modeling
procedures\footnote{For example, stationary lagged regression models
  that assume stable means and variances over time (incl., vector
  \change{autoregression}{autoregressive} models, dynamic structural
  equation models, autoregressive integrated moving average models, and
  cross-lagged panel analyses) or basic trajectory models (e.g., mixed
  effects models, spline regression models, and latent growth curve
  modeling).}. And while inferential model testing is certainly
important, we still miss discussions of methods for the more fundamental
task of describing, summarizing, and understanding the developmental
data patterns.

As an example, little data has thus far investigated the development of
migration experiences and no research has assessed the co-development of
multiple experience aspects. Yet, understanding how people differ in
their migration trajectories, can be crucial in understanding adaptive
and maladaptive patterns. \remove{We we need}\change{t}{T}o identify
which variables are most important in the adaptation of migrants
\add{over time}, we need methods to
\change{identify clusters of similar individuals and developments}{break down the data heterogeneity into its core components (in terms of important variables and developments)}
and we need \change{
to assess whether such clusters differ in}{ways to identify how these core components relate to}
key adaptation markers (including, well-being, intergroup anxiety,
outgroup trust, or societal participation). There is, thus, a clear need
to assess the utility of analysis procedures focused on the description
and understanding of complex dynamical data.

In this manuscript, we aim to assess the utility of one such promising
analysis for the use of social psychological experience sampling data.
Recent studies have laid out the potential effectiveness of dimension
reduction procedures, which can address the new forms of person-,
variable-, and time point heterogeneity jointly \citep[i.e., three-mode
principle component analyses, 3MPCA; e.g.,][]{Monden2015}.

\change{We will, particularly,}{To this aim, we will} analyse the data
from three experience sampling studies, which followed the migration
experiences of recent migrants to the Netherlands.
\add{All three studies focus on the psychological adaptation of migrants (i.e., psychological acculturation). However, given that past investigations of psychological acculturation have underexplored the crucial aspect of motivational experiences}
\citep{Kreienkamp2022d}\add{, the three studies have places a particular emphasis on the needs, goals, and motives of young migrants.}

\hypertarget{hypotheses}{%
\subsection{Hypotheses}\label{hypotheses}}

We do not have hypotheses in the traditional sense. Our analysis plan is
based on the aim of describing, summarizing, and understanding a complex
data set of extensive longitudinal data. We propose that the dimension
reduction procedure we employ will identify meaningful patterns and
developments within the data, which are useful to migration researchers
and practitioners.

\hypertarget{design-plan}{%
\section{Design Plan}\label{design-plan}}

\hypertarget{study-type}{%
\subsection{Study type}\label{study-type}}

\textbf{Observational Study}. Data is collected from study subjects that
are not randomly assigned to a treatment. This includes surveys, natural
experiments, and regression discontinuity designs.
\note{Note: This is part of the OSF dropdown answer and we can't change the description.}

\hypertarget{blinding}{%
\subsection{Blinding}\label{blinding}}

No participant blinding is involved in this study.

\hypertarget{study-design}{%
\subsection{Study design}\label{study-design}}

All three
studies\note{Note: I now extended the introduction of the three studies in the end of the description section. So I hope this doesn't come out of the blue as much anymore.}
used an extensive longitudinal design. Using a daily diary format, for
at least 30 days participants received a short survey twice per day (at
around 12pm and 7pm). We additionally included a longer pre- and post
measurement survey the days before and after the extensive longitudinal
data collection.

\hypertarget{randomization}{%
\subsection{Randomization}\label{randomization}}

No randomization is involved in this study.

\hypertarget{sampling-plan}{%
\section{Sampling Plan}\label{sampling-plan}}

\hypertarget{existing-data}{%
\subsection{Existing data}\label{existing-data}}

\textbf{Registration following analysis of the data}: As of the date of
submission, you have accessed and analyzed some of the data relevant to
the research plan. This includes preliminary analysis of variables,
calculation of descriptive statistics, and observation of data
distributions. Please see cos.io/prereg for more information.

\hypertarget{explanation-of-existing-data}{%
\subsection{Explanation of existing
data}\label{explanation-of-existing-data}}

The data was collected as part of a larger collaboration on daily
intergroup relations. A sub-sample of variables has recently been
accessed by the research team for an unrelated analysis
\citep{Kreienkamp2022b}. Additionally, several of the variables were
prepared for a graphical presentation of the dataset. Thus far, none of
the proposed analyses have been conducted and none of the previous
analyses have been related to dimension reductions
\change{or longitudinal trajectories}{nor have any of the past analyses analysed the longitudinal nature of the data}.

\hypertarget{data-collection-procedures}{%
\subsection{Data collection
procedures}\label{data-collection-procedures}}

\add{We collected three experience sampling studies, following the daily migration experiences of young migrants, who had recently arrived in the Netherlands. }For
all three studies, the data was collected in a three-step procedure:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Entry Survey: A pre-measurement questionnaire (appr. 25 minutes)
  including demographic information, and relations to the Dutch majority
  (payment: 2 Euros).
\item
  Experience Recaps: At least 30 days of short reflection surveys (appr.
  3---5 minutes) on intergroup interactions twice a day (payment: 1 Euro
  per Recap; up to 2 Euros per day).
\item
  Conclusion Survey: On the last day, we conclude with a
  post-measurement questionnaire (appr. 25 minutes) with some questions
  on habits and reflections on the study (payment: 2 Euros).
\end{enumerate}

For the third study, participants had the option of continuing the study
for an unspecified amount of time. After the initial 30 day duration,
participants were offered the possibility to continue participating in
the study either with payment if daily diary measures were missed during
the initial study phase or without payment after a total of 60 daily
diary measurements were completed. After the initial 30-day period,
participants receive automated feedback visualizing the development of
their own well-being, attitudes, and motive responses as an additional
initiative and to give participants access to their own data and to
compensate study participation.

\hypertarget{sample-size}{%
\subsection{Sample size}\label{sample-size}}

For Study 1 (initial preliminary study) our target sample size is a sum
of 1,000 daily diary measurements. As we expected a completion rate of
around 80\% we aimed to recruite 20 participants (20 participants X 50
measurements). We further over-sampled slightly to compensate for
potential drop outs given the length and intensity of the study.
\add{The total collected sample size was thus 23 participants.}

We then used several key relationships (relevant to the broader research
team) to estimate sufficient power for a range of different analyses
(i.e., using power simulations). Based on these power simulations, for
Studies 2 and 3, our target sample size was a sum of 4,000 daily diary
measurements. With 100\% completion rate that would be archived with 67
participants (60 daily diary responses each). Given that we expect some
incomplete daily diary measurements, we aimed to recruit 80
participants. For \change{both studies}{Studies 2 and 3,} we again aimed
to over-sampled slightly to account for expected drop outs.
\add{We were ultimately able to recruited a total of 113 particpants for Study 2 and 71 participants for Study 3.}

\hypertarget{sample-size-rationale}{%
\subsection{Sample size rationale}\label{sample-size-rationale}}

The targeted sample size depended on a combination of different factors.
Different analyses were planned as part of the collaboration and
budgeting was a practical constraint. Some analyses were planned based
on (1) the pre- to post measurements, (2) the dynamic developments over
the daily diary measurements, or (3) the contemporary effects within the
daily diary measurements.

Power considerations of mixed effects model such as with extensive
longitudinal data are difficult to estimate because of the complex
covariance structures. Simulation studies based on the first sample
within this project indicated that with well-distributed scales, and
small to medium effect sizes, 70-80 participants with at least seven
daily diary measurements and a simple pre--post survey were sufficiently
powerful (power = .8, alpha = .05) to answer most of the key research
questions of the collaboration.

The ultimate sampling procedure decision was made as a practical
balancing of the number of participants and the number of measurements
provided by each participants.

\hypertarget{stopping-rule}{%
\subsection{Stopping rule}\label{stopping-rule}}

Participants were recruited until the targeted number of participant
finished the pre-measurement. Invitations to complete additional daily
diary measurements (in Study 3) were extended until participants chose
to leave the study or at the most until two months (i.e., 64 days) after
the initial entry survey (i.e., from the pre measurement survey).

\hypertarget{variables}{%
\section{Variables}\label{variables}}

\hypertarget{manipulated-variables}{%
\subsection{Manipulated variables}\label{manipulated-variables}}

Not applicable given that the study design is observational.

\hypertarget{measured-variables}{%
\subsection{Measured variables}\label{measured-variables}}

Given the circumstance that we utilize three independent experience
sampling studies for our analyses, the variables are at times slightly
different between studies. Additionally, given that the analysis we aim
to undertake (i.e., 3MPCA) uses a large number of variables for the
multiple imputations, dimension reduction, and correlational analyses,
we will not list all items individually. Instead, we provide full
variable information in the following data sheets:
`VariableSelectionDaily.xlsx' and `VariableSelectionPrePost.xlsx'.

\textbf{Key variables}\\
\add{While} most of the variables are identical across all studies,
\remove{however} some differ slightly in content or wording. However,
for each study we aimed to collect the following types of variables.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Motivational variables

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    core motive fulfillment (i.e., ``\emph{During your interaction with
    -X- (/this morning) your goal (-TEXT-) was fulfilled.}'')
  \item
    goal importance ratings of 10 individual goals (e.g., ``\emph{career
    goals}'', ``\emph{health / fitness goals}'')
  \item
    self determination theory needs (i.e., autonomy, relatedness,
    competence)
  \end{enumerate}
\item
  Affective states

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    experienced well-being (happiness, energy)
  \item
    general emotional state scale (e.g., ``\emph{How do you feel right
    now? not angry at all to very angry}'')
  \end{enumerate}
\item
  Behavioral self-reports (Studies 2 and 3)

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    pro-social behavior (e.g., ``\emph{Made demeaning, rude or
    derogatory remarks about someone.}'')
  \item
    anti-social behavior (e.g., ``\emph{I was there to listen to
    someone's problems.}'')
  \end{enumerate}
\item
  Cognitive measures

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    outgroup attitude (``\emph{After the interaction, how favorably do
    you feel towards \ldots{} / At the moment, how favorably do you feel
    towards \ldots{} the Dutch.}'')
  \item
    Allport's contact condition perceptions (i.e., equal status, shared
    goal, cooperative, voluntary)
  \item
    interaction quality ratings (e.g., ``\emph{Overall, the interaction
    was\ldots{} Unpleasant to Pleasant}'')
  \end{enumerate}
\end{enumerate}

It should be noted, that we collected substantially more motivational
and affecive variables, as they have been understudied in the past.

\textbf{Interpretation correlation variables}\\
To interpret the \add{person-mode} components identified by the 3MPCA,
we would like to correlate the component scores with a range of person-
or time point specific variables. While the full list of variables is
available in the accompanying data sheets (see
`VariableSelectionDaily.xlsx' and `VariableSelectionPrePost.xlsx'), we
provide a few examples of the targeted categories below.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  demographic variables

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    age
  \item
    gender
  \item
    \ldots{}
  \end{enumerate}
\item
  societal participation

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    language comprehension and -use
  \item
    work inclusion
  \item
    \ldots{}
  \end{enumerate}
\item
  adaptation indicators

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    social identification
  \item
    intergroup anxiety
  \item
    \ldots{}
  \end{enumerate}
\item
  everyday life obstacles

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    discrimination experiences
  \item
    negative life events
  \item
    \ldots{}
  \end{enumerate}
\item
  individual differences

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    big five personality scores
  \item
    attachment style
  \item
    \ldots{}
  \end{enumerate}
\end{enumerate}

\textbf{Auxiliary variables for multiple imputation}\\
For the missing data imputation we follow the procedure reported by
\citet{Monden2015}, and include any pre-, post-, or daily dairy
variables that are significantly (\(p\) \textless{} .01) and
meaningfully (\(r\) \textgreater{} .3) correlated with either the key
variables or missingness on the key variables. For an overview of the
variables that qualify as auxiliary variables see the enclosed data
sheets (see `VariableSelectionDaily.xlsx' and
`VariableSelectionPrePost.xlsx'). Additional information about the
multiple imputation procedure is also available at
\protect\hyperlink{statistical-models}{Statistical models} 2.

\emph{We also provide an exemplary codebook (using Study 3 as an
example; see `Codebook\_AOT-M\_ItemsPerSection.xlsx'). The full survey
files will be available as part of the main OSF repository connected to
this preregistration.}

\hypertarget{indices}{%
\subsection{Indices}\label{indices}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Mean Allport's conditions. We create a mean-averaged index of
  Allport's conditions in response to past findings indicating that the
  conditions are best conceptualized jointly and as functioning together
  rather than as fully independent factors
  \citep[p.~766]{Pettigrew2006}. Similar to past studies we thus hope to
  build a global indicator \citep[e.g., see][]{Pettigrew2006}. As with
  other indices we will ensure that the individual items indeed relate
  to a common latent construct and are meaningfully combine\add{d} in an
  index. If this is not possible we will create sub-indices and/or
  assess the impact of the conditions separately.

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    The interaction with {[}name interaction partner{]} was on equal
    footing (same status)
  \item
    {[}name interaction partner{]} shared your goal ({[}free-text entry
    interaction key need{]})
  \item
    The interaction with {[}name interaction partner{]} was cooperative
  \item
    The interaction with {[}name interaction partner{]} was voluntary
  \end{enumerate}
\item
  Mean belongingness during intergroup contact

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    I shared information about myself.
  \item
    {[}name interaction partner{]} shared information about themselves.
  \end{enumerate}
\item
  Mean alternative interaction quality definition (``Overall, the
  interaction with {[}name interaction partner{]} was \ldots{}'')

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    Unpleasant to Pleasant
  \item
    Superficial to Meaningful
  \item
    Ineffective to Effective
  \item
    Unimportant to Important
  \end{enumerate}
\item
  Mood Subscales (MDMQ)

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    alertness
  \item
    calmness
  \item
    valence
  \end{enumerate}
\item
  Mean anti-social behaviors

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    Put someone down
  \item
    Show little attention in someones opinion
  \item
    Demeaning remarks
  \item
    Inappropriately addressing someone
  \item
    Ignored or excluded someone
  \item
    Doubt someones judgement
  \item
    Unwanted attempts of personal matters
  \end{enumerate}
\item
  Mean pro-social behaviors

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    Listen to someones problems
  \item
    Cheer someone up
  \item
    Help someone get things done
  \item
    Help someone with responsibilities
  \end{enumerate}
\end{enumerate}

Additionally, in the pre- and post-measurement surveys are several
validated scales that we will combine into their sub-scales. Indices
will be created in line with the accompanying validation literature:

\add{Added:}

\fbox{\parbox{\mylength}{
  \color{editPurple}
  \textbf{Note.}\\
  We have a group of six variables that are consistent across all three studies. Additionally, we have a number of variables that are either only relevant to a single study or a subset of the studies. If we agree on the study consolidation procedure as it is described below, I would suggest that we focus on the variables we have in all studies, and will include the other variables in the follow-up analyses and report only significant correlations (after alpha correction). I would also suggest that we add the list below to one of the variable selection files (Excel) instead of listing them all here (to avoid unnecessary confusion).
  \color{black}
}}

\color{editPurple}

Study 1 only:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Acculturation, Habits, and Interests Multicultural Scale for
  Adolescents (AHIMSA; S1)
\item
  Vancouver Index of Acculturation (VIA; S1)
\item
  Situational Self Awareness Scale (SAS; S1)
\end{enumerate}

Study 3 only:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Outgroup Trust
\item
  Work Group Inclusion
\item
  Meaningful Life Scale
\item
  Big Five Personality Questionnaire
\item
  Attachment Styles Scale
\item
  Paranoia Scale
\end{enumerate}

Studies 1 and 2:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Self Determination Theory Scale (SDT; S1, S2)
\item
  Interpersonal Support Evaluation List (ISEL; S1, S2)
\item
  Perceived Stress Scale (PSS; S1, S2)
\item
  Negative Life Events Scale (NLES; S1, S2)
\end{enumerate}

Studies 2 and 3:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Social Identification Scale (S2, S3)
\item
  Multidimensional Mood State Questionnaire (MDMQ; S2, S3)
\item
  Homesickness Scale (S2, S3)
\end{enumerate}

All Studies:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Intergroup Anxiety Scale (IAS)
\item
  The Satisfaction with Life Scale (SWL)
\item
  Rosenberg Self-Esteem Scale (SES)
\item
  Everyday Discrimination Scale
\item
  Language Proficiency
\item
  Association Participation
\end{enumerate}

\color{black}

\hypertarget{analysis-plan}{%
\section{Analysis Plan}\label{analysis-plan}}

\hypertarget{statistical-models}{%
\subsection{Statistical models}\label{statistical-models}}

For our analysis, we adapt the procedures outlined by
\citet{Monden2015}:

\fbox{\parbox{\mylength}{
  \color{editPurple}
  \textbf{Main Data Splits:}
  \begin{enumerate}
    \item \textbf{Three studies (S1, S2, S3)}
      \begin{enumerate}
        \item Combined for most power in correlations (including, correlation with study indicator)
        \item Separate in follow up analysis to ensure that we do not have a simpson's paradox
        \item Explore additional ideosyncratic variables in separated follow up
      \end{enumerate}
    \item \textbf{Two question types (interaction, no interaction)}:
      \begin{enumerate}
        \item Combined for most power in correlations (including, correlation with interaction indicator)
        \item Separate in subgroup follow up analysis to ensure that we do not have a simpson's paradox
      \end{enumerate}
    \item \textbf{Three time scales (half-day, day, week)}
      \begin{enumerate}
        \item If all variables clearly show single most variance on the same time-scale, single analysis only
        \item If multiple time-scales are possible within single analysis, single analysis only (see question box below)
        \item If variance split across multiple time scales for substantial number of variables (> 1/4 of all variables), multiple analyses for the different time scales 
      \end{enumerate}
    \item \textbf{Multiple Imputation (20 imputations)}
      \begin{enumerate}
        \item Test stability
        \item Split-half analysis
        \item Combine after analysis
      \end{enumerate}
  \end{enumerate}
  \color{black}
}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Sample Selection.} \add{For} our sample selection
  \remove{consists of three main steps. We (a) aggregate the key variables over time to archive a reasonably interpretable number of time points and the remove a first proportion of missing data. }we
  address both the selection of time points and participants. Given that
  multiple imputation procedures even work well with large proportions
  of missing data {[}assuming missingness at random;
  \citet{Madley-Dowd2019}{]}, we decided on a general criterion of less
  than 45\% missingness to balance sample size retention and bias in the
  multiple imputation model. Thus, we then \remove{(b)} select the time
  points for which we have \textbackslash change\{responses from 55\% of
  the participants\}\{less than 45\% missingness\} and \remove{(c)}
  select participants who have \textbackslash change\{responded to at
  least 55\% of the surveys\}\{less than 45\% missingness\} across the
  selected time range.
  \add{Because the studies are comparable but not identical in their sampling strategy, question selection, and question wording, we also have to consider, whether to combine the samples. }
\item
  \textbf{Time point aggregation:}
  \add{We then aggregate the key variables over time to archive a reasonably interpretable number of time points and remove a first proportion of missing data.}
  Given that little data is available on the meaningful time scales of
  the selected psychological variables, we chose to determine the
  appropriate time scales using variance decomposition \citep[e.g.,
  see][]{Ram2014}. This is to say that we create multi-level
  unconditional means models (without predictors) that include possible
  nested time scales as levels.
  \change{We, for example, assess the explained variances for measurements nested in days, nested in weeks, nested in months.}{We chose to select time scales that align with common human cycles. We thus compare the variances of bi-daily, daily, and weekly aggregations. Additional aggregations of two weeks or the full four weeks might be possible but would most likely reduce the variance too much for any meaningul further reduction during the 3MPCA.}
  We then chose the ideal time scale for each of the key variables.
\end{enumerate}

\fbox{\parbox{\mylength}{
  \color{editPurple}
  \textbf{Note:} I talked about the individual time scales with Rei. And one issue that came up was that although the time points do not have to be equidistal between measurement ocasions, each variable needs to have data at each measured time point and the time scales should be equal across variables. This would mean that we will need to have the same time scale (e.g., daily) for all variables. Given that we have now only three time scales (i.e., bi-daily, daily, weekly) we could run the 3MPCA for all three time scales and assess differences (in a multi-verse style analysis).\\
  \textbf{Question:} I am not entirely sure I fully understand yet why it is not possible to aggregate items across different time windows as long as data is available for all time points. For example, if energy levels are kept at bi-daily measurements but for well-being we calculate a daily average, we could then replace both daily time points of well-being with the daily average. I understand that this sounds a bit silly because we give up the morning/afternoon variance but it might still be useful in terms of missingess reduction. Here my confused thoughts: Does this mean that 3MPCA cannot deal with variables that change at different speeds? Is this because the time components are estimated across all variables and might be mis-specified if we have different time scales? This seems counter my current understanding of the core array (i.e., interactions between the components) where time components could interact with variable components.\\
  Long story short: Maybe we can discuss this issue again, I feel like I might have misunderstood something somewhere :-D\\
  Sorry...
  \color{black}
}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \textbf{Multiple Imputation.} We then create 20 imputed datasets to
  perform the analyses on. As outlined by \citet{Monden2015}, we will
  use the key variables themself as well as auxiliary variables to
  impute missing values. Auxiliary variables are any pre-, post-, or
  daily dairy variables that are significantly (\(p\) \textless{} .01)
  and meaningfully (\(r\) \textgreater{} .3) correlated with (1) the key
  variables or (2) missingness on the key variables.
\item
  \textbf{Three-way ANOVA.} We assess the percentages of explained
  variance for the person-, variable-, and time aspects --- which offers
  an indication of whether a 3MPCA is useful for the dataset. Based on
  the grand mean centered variables we conduct a fixed-effects three-way
  ANOVA of the person-, variable-, and time modes as well as their
  various interactions. We are particularly interested in the highest
  order interaction term Person * Variable * Time + error, as a large
  amount of variance in this effect would speak towards the
  interdependence of the three modes.
\item
  \textbf{Data preprocessing.} For the \change{three mode }{3M}PCA, we
  center (across participants but within time point) and normalize
  (within variable but across time points) all key variables. The
  between-person centering, ensures that all variations are around the
  mean trend (which is removed by the centering). The normalization
  within variable are important for ensuring equal variances across
  variables, which ensures equal weighting of the variables in the
  3MPCA. For methodological detail see
  \protect\hyperlink{transformations}{Transformations}.
\item
  \textbf{Selection of 3MPCA model complexity} We then run the 3MPCA. We
  use a generalized scree plot to select the appropriate number of
  components for each of the three modes (i.e., person, variable, time).
  To test the stability of the solution results are compared across the
  20 imputed datasets \add{and split-half stability is assessed}.
\item
  \textbf{3MPCA model fitting.} For the selected complexities we then
  extract simple component structures (i.e., for each mode individually)
  as well as the \change{array core}{core array} (the full 3MPCA array,
  which
  \change{holds the weights of all combinations of the three modes}{specifies all combinations of the three mode components}).
  A Joint Orthomax orthogonal rotation and standard weights
  \remove{(when necessary)} are used to extract human interpretable
  component scores. This procedure is done on all 20 imputed data sets.
\item
  \textbf{Generalized Procrustes rotation.} In order to combine the
  three individual component structure from the 20 data sets, we use a
  generalized Procrustes rotation --- calculating the average of each
  compontent and core array.
\item
  \textbf{Explained variance.} As fit indices we then calculate (1) fit
  percentage of the estimated array for each imputed data set (i.e.,
  explained variance around the removed general trend) as well as (2) an
  \emph{overall} fit percentage of the estimated array (i.e., explained
  variance including the general trend). Both these fit metrices should
  give an indication of how much of the original variance the reduced
  component structure was able to capture.
\item
  \textbf{Component interpretation} To embed and interpret the resulting
  components (especially the person components), we calculate
  correlations of the component scores with key adaptation markers
  (including, well-being, anxiety, trust, or societal inclusion). If
  components remain unclear still we can additionally perform k-means
  clustering on the lower dimensional space to identify clearer groups,
  which can be compared on the adaptation markers if necessary.
\end{enumerate}

\hypertarget{transformations}{%
\subsection{Transformations}\label{transformations}}

\setlength{\abovedisplayskip}{0pt}
\setlength{\belowdisplayskip}{0pt}
\setlength{\abovedisplayshortskip}{0pt}
\setlength{\belowdisplayshortskip}{0pt}

For three-mode PCA it is custom to center (across participants but
within time point) and to normalize (within variable but across time
points). This is done to create a meaningful zero value for each time
point (to compare participants) and a variance of 1 across all time
points of a variable (ensuring equal weightin of variables in the
3MPCA).

We provide the main equations of the procedure below, where individual
\(i\) (\(i = 1,\ ...,\ I\)) reported
variable\change{ $k$ ($k = 1,\ ...,\ K$)}{ $x$ and its naturalized form $z$ (where $[k = 1,\ ...,\ K]$ indexes all available variables)}
at time point \(t\) (\(t = 1,\ ...,\ T\)), so that \(I\)=number of
persons, \(K\)=number of items, \(T\)=number of time points within the
dataset. For further information as well as an example illustration see
Supplemental Material 3 in \citet{Monden2015}.

\begin{equation} \label{eq:Mean}
  \overline{x}_{kt} =  \sum_{i=1}^I x_{ikt}
\end{equation}

\begin{equation} \label{eq:NormalizationSd}
  \sigma_{k} =  \sqrt{\sum_{i=1}^I \sum_{k=1}^K \frac{(x_{ikt}-\overline{x}_{kt})^2}{I*T}}
\end{equation}

\begin{equation} \label{eq:NormalizedScore}
  z_{ikt} =  \frac{x_{ikt}-\overline{x}_{kt}}{\sigma_{k}}
\end{equation}

\hypertarget{inference-criteria}{%
\subsection{Inference criteria}\label{inference-criteria}}

Many of the proposed procedures are descriptive rather then inferential.
Importantly, we will use amounts of variances explained as our main fit
indices. If we perform inferential analyses, we will use the standard
p\textless.05 criteria for determining whether the correlation and
regression coefficients are statistically significant.
\add{We will use appropriate multiple-comparison corrections whenever multiple tests are performed.}
We will place particular emphasis on effect sizes
\add{(e.g., correlations) }in our interpretations of the results
wherever \change{necessary}{possible}.

\hypertarget{data-exclusion}{%
\subsection{Data exclusion}\label{data-exclusion}}

No checks will be performed to determine eligibility for inclusion
besides verification that each subject answered each of the variables of
interest for a given analysis. Outliers will generally be included in
analyses, however we will use sensitivity analyses to assess the
robustness of the results to outliers.

\hypertarget{missing-data}{%
\subsection{Missing data}\label{missing-data}}

The sample selection based on proportions of missing data and the
multiple imputation procedures are described in
\protect\hyperlink{statistical-models}{Statistical models}.

\hypertarget{exploratory-analyses-optional}{%
\subsection{Exploratory analyses
(optional)}\label{exploratory-analyses-optional}}

A recent alternative for trajectory dimension reduction has been the use
of LSTM auto encoders. The encoder decoder classification procedure has
the advantage of being extremely flexible in the use of the data set and
could be interpreted in a similar way as the 3MPCA (see
\protect\hyperlink{statistical-models}{Statistical models} 9).

\hypertarget{other}{%
\section{Other}\label{other}}

\hypertarget{other-optional}{%
\subsection{Other (Optional)}\label{other-optional}}

Not applicable.

\hypertarget{section}{%
\subsection{}\label{section}}

\vspace{-2pc}
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{-1in}
\setlength{\parskip}{8pt}

\noindent

\bibliography{../references.bib}

\end{document}
