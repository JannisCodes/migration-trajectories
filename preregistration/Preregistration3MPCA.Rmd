---
title           : "Migration Experience Trajectories: A Three Mode Principle Component Analysis"
shorttitle      : "Preregistration: Migration Experience Trajectories"
date            : "`r Sys.setlocale('LC_TIME', 'C'); format(Sys.time(), '%d\\\\. %B %Y')`"
author: 
  - name        : Jannis Kreienkamp
    affiliation : "1"
  - name        : Kai Epstude
    affiliation : "1"
  - name        : Rei Monden
    affiliation : "2"
  - name        : Maximilian Agostini
    affiliation : "1"
  - name        : Peter de Jonge
    affiliation : "1"
  - name        : Laura F. Bringmann
    affiliation : "1"
affiliation:
  - id          : 1
    institution : University of Groningen, Department of Psychology
  - id          : 2
    institution : Hiroshima University, Graduate School of Advanced Science and Engineering
bibliography: "../references.bib"
csl: apa.csl
biblio-style: "apalike" 
output: 
  prereg::cos_prereg:
    citation_package: natbib
    keep_tex:  true
editor_options: 
  chunk_output_type: console
header-includes:
   - \usepackage{amsmath}
   - \usepackage{nccmath}
   - \usepackage{LatexPackage/trackchanges}
   # - \usepackage[finalnew]{LatexPackage/trackchanges}
   # - \usepackage[finalold]{LatexPackage/trackchanges}
   # - \usepackage[inline]{LatexPackage/trackchanges}
   - \usepackage[usenames,dvipsnames]{xcolor}
   - \addeditor{Jannis}
---

\newlength{\mylength}
\setlength{\fboxsep}{15pt}
\setlength{\mylength}{\linewidth}
\addtolength{\mylength}{-2\fboxsep}
\addtolength{\mylength}{-2\fboxrule}
\definecolor{editPurple}{RGB}{84, 28, 117}

```{r setup, include=FALSE}
# R Studio Clean-Up
  cat("\014") # clear console
  #rm(list=ls()) # clear workspace - use restart R instead [cmd/alt + shift + F10]
  gc() # garbage collector
  
# Install and Load Packages
# !IMPORTANT!
# BEFORE FIRST RENDER:
# To install all relevant packages please run "renv::restore()" (or renv::init() and then initiate from lockfile) in the console before the first use to ensure that all packages are using the correct version.
# to store the packages in a contained library within the project folder: renv::settings$use.cache(FALSE) and add 'RENV_CONFIG_SANDBOX_ENABLED = FALSE' to an '.Renviron' file 
lib <- c("rmarkdown", "knitr", "remedy", "bookdown", "psych",
         "ggplot2", "ggthemes", "haven", "RColorBrewer", "plotly", "gridExtra",
         "sessioninfo", "tibble", "pander", "devtools",
         "data.table", "dplyr", "tidyr", "Hmisc", "kableExtra", 
         "stringr", "stringi", "reshape2", "lubridate")
invisible(lapply(lib, library, character.only = TRUE))  
rm(lib)  

# Markdown Options
  knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # set working directory

# Global Chunk Options
  knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figures/',
                        echo=TRUE, warning=FALSE, message=FALSE)
```

# Study Information

## Title
<!-- Provide the working title of your study. It may be the same title that you submit for publication of your final manuscript, but it is not a requirement. The title should be a specific and informative description of a project. Vague titles such as 'Fruit fly preregistration plan' are not appropriate.

Example: Effect of sugar on brownie tastiness. -->

`r rmarkdown::metadata$title`


## Description
<!-- Please give a brief description of your study, including some background, the purpose of the of the study, or broad research questions. The description should be no longer than the length of an abstract. It can give some context for the proposed study, but great detail is not needed here for your preregistration.

Example: Though there is strong evidence to suggest that sugar affects taste preferences, the effect has never been demonstrated in brownies. Therefore, we will measure taste preference for four different levels of sugar concentration in a standard brownie recipe to determine if the effect exists in this pastry. -->

Recent reviews have called for more comprehensive assessment of human experiences and for more longitudinal real-life data, within the psychological sciences more broadly and in migration research in particular [e.g., @Kreienkamp2022d; @MacInnis2015; @McKeown2017; @Pettigrew2011; @Ward2019]. However, while generally speaking analytical methods for such, more complex, data have become more readily available [e.g., @ODonnell2021], it remains unclear how we should identify key developmental patterns --- especially across multiple variables at the same time.

In essence, the novel extensive longitudinal datasets come with new forms of heterogeneity, where we have to consider differences between people, over time, and across variables. Yet, past analytical advances have almost exclusively pushed for top-down inferential modeling procedures^[For example, stationary lagged regression models that assume stable means and variances over time (incl., vector \change{autoregression}{autoregressive} models, dynamic structural equation models, autoregressive integrated moving average models, and cross-lagged panel analyses) or basic trajectory models (e.g., mixed effects models, spline regression models, and latent growth curve modeling).]. And while inferential model testing is certainly important, we still miss discussions of methods for the more fundamental task of describing, summarizing, and understanding the developmental data patterns.

As an example, little data has thus far investigated the development of migration experiences and no research has assessed the co-development of multiple experience aspects. Yet, understanding how people differ in their migration trajectories, can be crucial in understanding adaptive and maladaptive patterns. \remove{We we need}\change{t}{T}o identify which variables are most important in the adaptation of migrants \add{over time}, we need methods to \change{identify clusters of similar individuals and developments}{break down the data heterogeneity into its core components (in terms of important variables and developments)} and we need \change{
to assess whether such clusters differ in}{ways to identify how these core components relate to} key adaptation markers (including, well-being, intergroup anxiety, outgroup trust, or societal participation). There is, thus, a clear need to assess the utility of analysis procedures focused on the description and understanding of complex dynamical data. 

In this manuscript, we aim to assess the utility of one such promising analysis for the use of social psychological experience sampling data. Recent studies have laid out the potential effectiveness of dimension reduction procedures, which can address the new forms of person-, variable-, and time point heterogeneity jointly [i.e., three-mode principle component analyses, 3MPCA; e.g., @Monden2015]. 

\change{We will, particularly,}{To this aim, we will} analyse the data from three experience sampling studies, which followed the migration experiences of recent migrants to the Netherlands. \add{All three studies focus on the psychological adaptation of migrants (i.e., psychological acculturation). However, given that past investigations of psychological acculturation have underexplored the crucial aspect of motivational experiences} [@Kreienkamp2022d]\add{, the three studies have places a particular emphasis on the needs, goals, and motives of young migrants.}


## Hypotheses
<!-- List specific, concise, and testable hypotheses. Please state if the hypotheses are directional or non-directional. If directional, state the direction. A predicted effect is also appropriate here. If a specific interaction or moderation is important to your research, you can list that as a separate hypothesis.

Example: If taste affects preference, then mean preference indices will be higher with higher concentrations of sugar. -->

We do not have hypotheses in the traditional sense. Our analysis plan is based on the aim of describing, summarizing, and understanding a complex data set of extensive longitudinal data. We propose that the dimension reduction procedure we employ will identify meaningful patterns and developments within the data, which are useful to migration researchers and practitioners.    

# Design Plan
<!-- In this section, you will be asked to describe the overall design of your study. Remember that this research plan is designed to register a single study, so if you have multiple experimental designs, please complete a separate preregistration. -->


## Study type

**Observational Study**. Data is collected from study subjects that are not randomly assigned to a treatment. This includes surveys, natural experiments, and regression discontinuity designs.
\note{Note: This is part of the OSF dropdown answer and we can't change the description.}


## Blinding
<!-- Blinding describes who is aware of the experimental manipulations within a study. Select all that apply. Is there any additional blinding in this study? -->

No participant blinding is involved in this study.

## Study design
<!-- Describe your study design. Examples include two-group, factorial, randomized block, and repeated measures. Is it a between (unpaired), within-subject (paired), or mixed design? Describe any counterbalancing required. Typical study designs for observation studies include cohort, cross sectional, and case-control studies.

This question has a variety of possible answers. The key is for a researcher to be as detailed as is necessary given the specifics of their design. Be careful to determine if every parameter has been specified in the description of the study design. There may be some overlap between this question and the following questions. That is OK, as long as sufficient detail is given in one of the areas to provide all of the requested information. For example, if the study design describes a complete factorial, 2 X 3 design and the treatments and levels are specified previously, you do not have to repeat that information.

Example: We have a between subjects design with 1 factor (sugar by mass) with 4 levels. -->

All three studies\note{Note: I now extended the introduction of the three studies in the end of the description section. So I hope this doesn't come out of the blue as much anymore.} used an extensive longitudinal design. Using a daily diary format, for at least 30 days participants received a short survey twice per day (at around 12pm and 7pm). We additionally included a longer pre- and post measurement survey the days before and after the extensive longitudinal data collection.


## Randomization
<!-- If you are doing a randomized study, how will you randomize, and at what level? Typical randomization techniques include: simple, block, stratified, and adaptive covariate randomization. If randomization is required for the study, the method should be specified here, not simply the source of random numbers.

Example: We will use block randomization, where each participant will be randomly assigned to one of the four equally sized, predetermined blocks. The random number list used to create these four blocks will be created using the web applications available at https://random.org. -->

No randomization is involved in this study.


# Sampling Plan
<!-- In this section we’ll ask you to describe how you plan to collect samples, as well as the number of samples you plan to collect and your rationale for this decision. Please keep in mind that the data described in this section should be the actual data used for analysis, so if you are using a subset of a larger dataset, please describe the subset that will actually be used in your study. -->


## Existing data
<!-- Preregistration is designed to make clear the distinction between confirmatory tests, specified prior to seeing the data, and exploratory analyses conducted after observing the data. Therefore, creating a research plan in which existing data will be used presents unique challenges. Please select the description that best describes your situation. Please do not hesitate to contact us if you have questions about how to answer this question (prereg@cos.io). -->

<!-- **Registration prior to analysis of the data**. As of the date of submission, the data exist and you have accessed it, though no analysis has been conducted related to the research plan (including calculation of summary statistics). A common situation for this scenario when a large dataset exists that is used for many different studies over time, or when a data set is randomly split into a sample for exploratory analyses, and the other section of data is reserved for later confirmatory data analysis. -->

**Registration following analysis of the data**: As of the date of submission, you have accessed and analyzed some of the data relevant to the research plan. This includes preliminary analysis of variables, calculation of descriptive statistics, and observation of data distributions. Please see cos.io/prereg for more information.


## Explanation of existing data
<!-- If you indicate that you will be using some data that already exist in this study, please describe the steps you have taken to assure that you are unaware of any patterns or summary statistics in the data. This may include an explanation of how access to the data has been limited, who has observed the data, or how you have avoided observing any analysis of the specific data you will use in your study.

An appropriate instance of using existing data would be collecting a sample size much larger than is required for the study, using a small portion of it to conduct exploratory analysis, and then registering one particular analysis that showed promising results. After registration, conduct the specified analysis on that part of the dataset that had not been investigated by the researcher up to that point.

Example: An appropriate instance of using existing data would be collecting a sample size much larger than is required for the study, using a small portion of it to conduct exploratory analysis, and then registering one particular analysis that showed promising results. After registration, conduct the specified analysis on that part of the dataset that had not been investigated by the researcher up to that point. -->

The data was collected as part of a larger collaboration on daily intergroup relations. A sub-sample of variables has recently been accessed by the research team for an unrelated analysis [@Kreienkamp2022b]. Additionally, several of the variables were prepared for a graphical presentation of the dataset. Thus far, none of the proposed analyses have been conducted and none of the previous analyses have been related to dimension reductions \change{or longitudinal trajectories}{nor have any of the past analyses analysed the longitudinal nature of the data}.  


## Data collection procedures
<!-- Please describe the process by which you will collect your data. If you are using human subjects, this should include the population from which you obtain subjects, recruitment efforts, payment for participation, how subjects will be selected for eligibility from the initial pool (e.g. inclusion and exclusion rules), and your study timeline. For studies that donÍt include human subjects, include information about how you will collect samples, duration of data gathering efforts, source or location of samples, or batch numbers you will use.

The answer to this question requires a specific set of instructions so that another person could repeat the data collection procedures and recreate the study population. Alternatively, if the study population would be unable to be reproduced because it relies on a specific set of circumstances unlikely to be recreated (e.g., a community of people from a specific time and location), the criteria and methods for creating the group and the rationale for this unique set of subjects should be clear.

Example: Participants will be recruited through advertisements at local pastry shops. Participants will be paid $10 for agreeing to participate (raised to $30 if our sample size is not reached within 15 days of beginning recruitment). Participants must be at least 18 years old and be able to eat the ingredients of the pastries. -->

\add{We collected three experience sampling studies, following the daily migration experiences of young migrants, who had recently arrived in the Netherlands. }For all three studies, the data was collected in a three-step procedure:

1. Entry Survey: A pre-measurement questionnaire (appr. 25 minutes) including demographic information, and relations to the Dutch majority (payment: 2 Euros).
2. Experience Recaps: At least 30 days of short reflection surveys (appr. 3—5 minutes) on intergroup interactions twice a day (payment: 1 Euro per Recap; up to 2 Euros per day).
3. Conclusion Survey: On the last day, we conclude with a post-measurement questionnaire (appr. 25 minutes) with some questions on habits and reflections on the study (payment: 2 Euros).

For the third study, participants had the option of continuing the study for an unspecified amount of time. After the initial 30 day duration, participants were offered the possibility to continue participating in the study either with payment if daily diary measures were missed during the initial study phase or without payment after a total of 60 daily diary measurements were completed. After the initial 30-day period, participants receive automated feedback visualizing the development of their own well-being, attitudes, and motive responses as an additional initiative and to give participants access to their own data and to compensate study participation.

## Sample size
<!-- Describe the sample size of your study. How many units will be analyzed in the study? This could be the number of people, birds, classrooms, plots, interactions, or countries included. If the units are not individuals, then describe the size requirements for each unit. If you are using a clustered or multilevel design, how many units are you collecting at each level of the analysis? For some studies, this will simply be the number of samples or the number of clusters. For others, this could be an expected range, minimum, or maximum number.

Example: Our target sample size is 280 participants. We will attempt to recruit up to 320, assuming that not all will complete the total task. -->

For Study 1 (initial preliminary study) our target sample size is a sum of 1,000 daily diary measurements. As we expected a completion rate of around 80% we aimed to recruite 20 participants (20 participants X 50 measurements). We further over-sampled slightly to compensate for potential drop outs given the length and intensity of the study. \add{The total collected sample size was thus 23 participants.} 

We then used several key relationships (relevant to the broader research team) to estimate sufficient power for a range of different analyses (i.e., using power simulations). Based on these power simulations, for Studies 2 and 3, our target sample size was a sum of 4,000 daily diary measurements. With 100% completion rate that would be archived with 67 participants (60 daily diary responses each). Given that we expect some incomplete daily diary measurements, we aimed to recruit 80 participants. For \change{both studies}{Studies 2 and 3,} we again aimed to over-sampled slightly to account for expected drop outs. \add{We were ultimately able to recruited a total of 113 particpants for Study 2 and 71 participants for Study 3.}

## Sample size rationale
<!-- This could include a power analysis or an arbitrary constraint such as time, money, or personnel. This gives you an opportunity to specifically state how the sample size will be determined. A wide range of possible answers is acceptable; remember that transparency is more important than principled justifications. If you state any reason for a sample size upfront, it is better than stating no reason and leaving the reader to "fill in the blanks." Acceptable rationales include: a power analysis, an arbitrary number of subjects, or a number based on time or monetary constraints.

Example: We used the software program G*Power to conduct a power analysis. Our goal was to obtain .95 power to detect a medium effect size of .25 at the standard .05 alpha error probability. -->

The targeted sample size depended on a combination of different factors. Different analyses were planned as part of the collaboration and budgeting was a practical constraint. Some analyses were planned based on (1) the pre- to post measurements, (2) the dynamic developments over the daily diary measurements, or (3) the contemporary effects within the daily diary measurements.

Power considerations of mixed effects model such as with extensive longitudinal data are difficult to estimate because of the complex covariance structures. Simulation studies based on the first sample within this project indicated that with well-distributed scales, and small to medium effect sizes, 70-80 participants with at least seven daily diary measurements and a simple pre--post survey were sufficiently powerful (power = .8, alpha = .05) to answer most of the key research questions of the collaboration.

The ultimate sampling procedure decision was made as a practical balancing of the number of participants and the number of measurements provided by each participants. 

## Stopping rule
<!-- If your data collection procedures do not give you full control over your exact sample size, specify how you will decide when to terminate your data collection. 

You may specify a stopping rule based on p-values only in the specific case of sequential analyses with pre-specified checkpoints, alphas levels, and stopping rules. Unacceptable rationales include stopping based on p-values if checkpoints and stopping rules are not specified. If you have control over your sample size, then including a stopping rule is not necessary, though it must be clear in this question or a previous question how an exact sample size is attained.

Example: We will post participant sign-up slots by week on the preceding Friday night, with 20 spots posted per week. We will post 20 new slots each week if, on that Friday night, we are below 320 participants. -->

Participants were recruited until the targeted number of participant finished the pre-measurement. Invitations to complete additional daily diary measurements (in Study 3) were extended until participants chose to leave the study or at the most until two months (i.e., 64 days) after the initial entry survey (i.e., from the pre measurement survey).

# Variables
<!-- In this section you can describe all variables (both manipulated and measured variables) that will later be used in your confirmatory analysis plan. In your analysis plan, you will have the opportunity to describe how each variable will be used. If you have variables which you are measuring for exploratory analyses, you are not required to list them, though you are permitted to do so. -->


## Manipulated variables
<!-- Describe all variables you plan to manipulate and the levels or treatment arms of each variable. This is not applicable to any observational study. For any experimental manipulation, you should give a precise definition of each manipulated variable. This must include a precise description of the levels at which each variable will be set, or a specific definition for each categorical treatment. For example, “loud or quiet,” should instead give either a precise decibel level or a means of recreating each level. 'Presence/absence' or 'positive/negative' is an acceptable description if the variable is precisely described.

Example: We manipulated the percentage of sugar by mass added to brownies. The four levels of this categorical variable are: 15%, 20%, 25%, or 40% cane sugar by mass. -->

Not applicable given that the study design is observational.


## Measured variables
<!-- Describe each variable that you will measure. This will include outcome measures, as well as any predictors or covariates that you will measure. You do not need to include any variables that you plan on collecting if they are not going to be included in the confirmatory analyses of this study.

Observational studies and meta-analyses will include only measured variables. As with the previous questions, the answers here must be precise. For example, 'intelligence,' 'accuracy,' 'aggression,' and 'color' are too vague. Acceptable alternatives could be 'IQ as measured by Wechsler Adult Intelligence Scale' 'percent correct,' 'number of threat displays,' and 'percent reflectance at 400 nm.'

Example: The single outcome variable will be the perceived tastiness of the single brownie each participant will eat. We will measure this by asking participants ‘How much did you enjoy eating the brownie’ (on a scale of 1-7, 1 being 'not at all', 7 being 'a great deal') and 'How good did the brownie taste' (on a scale of 1-7, 1 being 'very bad', 7 being 'very good'). -->

Given the circumstance that we utilize three independent experience sampling studies for our analyses, the variables are at times slightly different between studies. Additionally, given that the analysis we aim to undertake (i.e., 3MPCA) uses a large number of variables for the multiple imputations, dimension reduction, and correlational analyses, we will not list all items individually. Instead, we provide full variable information in the following data sheets: 'VariableSelectionDaily.xlsx' and 'VariableSelectionPrePost.xlsx'. 

**Key variables**  
\add{While} most of the variables are identical across all studies, \remove{however} some differ slightly in content or wording. However, for each study we aimed to collect the following types of variables.   

1. Motivational variables
    a. core motive fulfillment (i.e., "_During your interaction with -X- (/this morning) your goal (-TEXT-) was fulfilled._")
    a. goal importance ratings of 10 individual goals (e.g., "_career goals_", "_health / fitness goals_")
    a. self determination theory needs (i.e., autonomy, relatedness, competence)
1. Affective states
    a. experienced well-being (happiness, energy)
    a. general emotional state scale (e.g., "_How do you feel right now? not angry at all to very angry_")
1. Behavioral self-reports (Studies 2 and 3)
    a. pro-social behavior (e.g., "_Made demeaning, rude or derogatory remarks about someone._")
    a. anti-social behavior (e.g., "_I was there to listen to someone's problems._")
1. Cognitive measures
    a. outgroup attitude ("_After the interaction, how favorably do you feel towards … / At the moment, how favorably do you feel towards …  the Dutch._")
    a. Allport's contact condition perceptions (i.e., equal status, shared goal, cooperative, voluntary)
    a. interaction quality ratings (e.g., "_Overall, the interaction was... Unpleasant to Pleasant_")  

It should be noted, that we collected substantially more motivational and affecive variables, as they have been understudied in the past.

**Interpretation correlation variables**  
To interpret the \add{person-mode} components identified by the 3MPCA, we would like to correlate the component scores with a range of person- or time point specific variables. While the full list of variables is available in the accompanying data sheets (see 'VariableSelectionDaily.xlsx' and 'VariableSelectionPrePost.xlsx'), we provide a few examples of the targeted categories below.  

1. demographic variables
    a. age
    a. gender
    a. ...
1. societal participation
    a. language comprehension and -use
    a. work inclusion
    a. ...
1. adaptation indicators
    a. social identification
    a. intergroup anxiety
    a. ...
1. everyday life obstacles
    a. discrimination experiences
    a. negative life events
    a. ...
1. individual differences
    a. big five personality scores
    a. attachment style
    a. ...


**Auxiliary variables for multiple imputation**  
For the missing data imputation we follow the procedure reported by @Monden2015, and include any pre-, post-, or daily dairy variables that are significantly ($p$ < .01) and meaningfully ($r$ > .3) correlated with either the key variables or missingness on the key variables. For an overview of the variables that qualify as auxiliary variables see the enclosed data sheets (see 'VariableSelectionDaily.xlsx' and 'VariableSelectionPrePost.xlsx'). Additional information about the multiple imputation procedure is also available at [Statistical models] 2.  

_We also provide an exemplary codebook (using Study 3 as an example; see 'Codebook_AOT-M_ItemsPerSection.xlsx'). The full survey files will be available as part of the main OSF repository connected to this preregistration._

## Indices
<!-- If any measurements are  going to be combined into an index (or even a mean), what measures will you use and how will they be combined? Include either a formula or a precise description of your method. If your are using a more complicated statistical method to combine measures (e.g. a factor analysis), you can note that here but describe the exact method in the analysis plan section.

If you are using multiple pieces of data to construct a single variable, how will this occur? Both the data that are included and the formula or weights for each measure must be specified. Standard summary statistics, such as "means" do not require a formula, though more complicated indices require either the exact formula or, if it is an established index in the field, the index must be unambiguously defined. For example, "biodiversity index" is too broad, whereas "Shannon’s biodiversity index" is appropriate.

Example: We will take the mean of the two questions above to create a single measure of 'brownie enjoyment.'  -->
˜
1. Mean Allport's conditions. We create a mean-averaged index of Allport's conditions in response to past findings indicating that the conditions are best conceptualized jointly and as functioning together rather than as fully independent factors [@Pettigrew2006, p. 766]. Similar to past studies we thus hope to build a global indicator [e.g., see @Pettigrew2006]. As with other indices we will ensure that the individual items indeed relate to a common latent construct and are  meaningfully combine\add{d} in an index. If this is not possible we will create sub-indices and/or assess the impact of the conditions separately.
    a. The interaction with [name interaction partner] was on equal footing (same status)
    a. [name interaction partner] shared your goal ([free-text entry interaction key need])
    a. The interaction with [name interaction partner] was cooperative
    a. The interaction with [name interaction partner] was voluntary
1. Mean belongingness during intergroup contact
    a. I shared information about myself. 
    a. [name interaction partner] shared information about themselves.
1. Mean alternative interaction quality definition ("Overall, the interaction with [name interaction partner] was ...")
    a. Unpleasant to Pleasant
    a. Superficial to Meaningful
    a. Ineffective to Effective
    a. Unimportant to Important
1. Mood Subscales (MDMQ)
    a. alertness
    a. calmness
    a. valence
1. Mean anti-social behaviors
    a. Put someone down
    a. Show little attention in someones opinion
    a. Demeaning remarks
    a. Inappropriately addressing someone
    a. Ignored or excluded someone
    a. Doubt someones judgement
    a. Unwanted attempts of personal matters
1. Mean pro-social behaviors
    a. Listen to someones problems
    a. Cheer someone up
    a. Help someone get things done
    a. Help someone with responsibilities
    
Additionally, in the pre- and post-measurement surveys are several validated scales that we will combine into their sub-scales. Indices will be created in line with the accompanying validation literature:

\add{Added:}

\fbox{\parbox{\mylength}{
  \color{editPurple}
  \textbf{Note.}\\
  We have a group of six variables that are consistent across all three studies. Additionally, we have a number of variables that are either only relevant to a single study or a subset of the studies. If we agree on the study consolidation procedure as it is described below, I would suggest that we focus on the variables we have in all studies, and will include the other variables in the follow-up analyses and report only significant correlations (after alpha correction). I would also suggest that we add the list below to one of the variable selection files (Excel) instead of listing them all here (to avoid unnecessary confusion).
  \color{black}
}}

\color{editPurple}

Study 1 only:

1. Acculturation, Habits, and Interests Multicultural Scale for Adolescents (AHIMSA; S1)
1. Vancouver Index of Acculturation (VIA; S1)
1. Situational Self Awareness Scale (SAS; S1)

Study 3 only:

1. Outgroup Trust
1. Work Group Inclusion
1. Meaningful Life Scale
1. Big Five Personality Questionnaire
1. Attachment Styles Scale
1. Paranoia Scale

Studies 1 and 2:

1. Self Determination Theory Scale (SDT; S1, S2)
1. Interpersonal Support Evaluation List (ISEL; S1, S2)
1. Perceived Stress Scale (PSS; S1, S2)
1. Negative Life Events Scale (NLES; S1, S2)

Studies 2 and 3:

1. Social Identification Scale (S2, S3)
1. Multidimensional Mood State Questionnaire (MDMQ; S2, S3)
1. Homesickness Scale (S2, S3)

All Studies:

1. Intergroup Anxiety Scale (IAS)
1. The Satisfaction with Life Scale (SWL)
1. Rosenberg Self-Esteem Scale (SES)
1. Everyday Discrimination Scale
1. Language Proficiency
1. Association Participation

\color{black}

# Analysis Plan
<!-- You may describe one or more confirmatory analysis in this preregistration. Please remember that all analyses specified below must be reported in the final article, and any additional analyses must be noted as exploratory or hypothesis generating.

A confirmatory analysis plan must state up front which variables are predictors (independent) and which are the outcomes (dependent), otherwise it is an exploratory analysis. You are allowed to describe any exploratory work here, but a clear confirmatory analysis is required. -->


## Statistical models
<!-- What statistical model will you use to test each hypothesis? Please include the type of model (e.g. ANOVA, multiple regression, SEM, etc) and the specification of the model (this includes each variable that will be included as predictors, outcomes, or covariates). Please specify any interactions, subgroup analyses, pairwise or complex contrasts, or follow-up tests from omnibus tests. If you plan on using any positive controls, negative controls, or manipulation checks you may mention that here. Remember that any test not included here must be noted as an exploratory test in your final article.

This is perhaps the most important and most complicated question within the preregistration. As with all of the other questions, the key is to provide a specific recipe for analyzing the collected data. Ask yourself: is enough detail provided to run the same analysis again with the information provided by the user? Be aware for instances where the statistical models appear specific, but actually leave openings for the precise test. See the following examples:

- If someone specifies a 2x3 ANOVA with both factors within subjects, there is still flexibility with the various types of ANOVAs that could be run. Either a repeated measures ANOVA (RMANOVA) or a multivariate ANOVA (MANOVA) could be used for that design, which are two different tests. 
- If you are going to perform a sequential analysis and check after 50, 100, and 150 samples, you must also specify the p-values you’ll test against at those three points.

Example:  We will use a one-way between subjects ANOVA to analyze our results. The manipulated, categorical independent variable is 'sugar' whereas the dependent variable is our taste index. -->

For our analysis, we adapt the procedures outlined by @Monden2015:

\fbox{\parbox{\mylength}{
  \color{editPurple}
  \textbf{Main Data Splits:}
  \begin{enumerate}
    \item \textbf{Three studies (S1, S2, S3)}
      \begin{enumerate}
        \item Combined for most power in correlations (including, correlation with study indicator)
        \item Separate in follow up analysis to ensure that we do not have a simpson's paradox
        \item Explore additional ideosyncratic variables in separated follow up
      \end{enumerate}
    \item \textbf{Two question types (interaction, no interaction)}:
      \begin{enumerate}
        \item Combined for most power in correlations (including, correlation with interaction indicator)
        \item Separate in subgroup follow up analysis to ensure that we do not have a simpson's paradox
      \end{enumerate}
    \item \textbf{Three time scales (half-day, day, week)}
      \begin{enumerate}
        \item If all variables clearly show single most variance on the same time-scale, single analysis only
        \item If multiple time-scales are possible within single analysis, single analysis only (see question box below)
        \item If variance split across multiple time scales for substantial number of variables (> 1/4 of all variables), multiple analyses for the different time scales 
      \end{enumerate}
    \item \textbf{Multiple Imputation (20 imputations)}
      \begin{enumerate}
        \item Test stability
        \item Split-half analysis
        \item Combine after analysis
      \end{enumerate}
  \end{enumerate}
  \color{black}
}}

1. **Sample Selection.** \add{For} our sample selection \remove{consists of three main steps. We (a) aggregate the key variables over time to archive a reasonably interpretable number of time points and the remove a first proportion of missing data. }we address both the selection of time points and participants. Given that multiple imputation procedures even work well with large proportions of missing data [assuming missingness at random; @Madley-Dowd2019], we decided on a general criterion of less than 45% missingness to balance sample size retention and bias in the multiple imputation model. Thus, we then \remove{(b)} select the time points for which we have \change{responses from 55% of the participants}{less than 45% missingness} and \remove{(c)} select participants who have \change{responded to at least 55% of the surveys}{less than 45% missingness} across the selected time range. \add{Because the studies are comparable but not identical in their sampling strategy, question selection, and question wording, we also have to consider, whether to combine the samples. }
2. **Time point aggregation:** \add{We then aggregate the key variables over time to archive a reasonably interpretable number of time points and remove a first proportion of missing data.} Given that little data is available on the meaningful time scales of the selected psychological variables, we chose to determine the appropriate time scales using variance decomposition [e.g., see @Ram2014]. This is to say that we create multi-level unconditional means models (without predictors) that include possible nested time scales as levels. \change{We, for example, assess the explained variances for measurements nested in days, nested in weeks, nested in months.}{We chose to select time scales that align with common human cycles. We thus compare the variances of bi-daily, daily, and weekly aggregations. Additional aggregations of two weeks or the full four weeks might be possible but would most likely reduce the variance too much for any meaningul further reduction during the 3MPCA.} 
We then chose the ideal time scale for each of the key variables.  

\fbox{\parbox{\mylength}{
  \color{editPurple}
  \textbf{Note:} I talked about the individual time scales with Rei. And one issue that came up was that although the time points do not have to be equidistal between measurement ocasions, each variable needs to have data at each measured time point and the time scales should be equal across variables. This would mean that we will need to have the same time scale (e.g., daily) for all variables. Given that we have now only three time scales (i.e., bi-daily, daily, weekly) we could run the 3MPCA for all three time scales and assess differences (in a multi-verse style analysis).\\
  \textbf{Question:} I am not entirely sure I fully understand yet why it is not possible to aggregate items across different time windows as long as data is available for all time points. For example, if energy levels are kept at bi-daily measurements but for well-being we calculate a daily average, we could then replace both daily time points of well-being with the daily average. I understand that this sounds a bit silly because we give up the morning/afternoon variance but it might still be useful in terms of missingess reduction. Here my confused thoughts: Does this mean that 3MPCA cannot deal with variables that change at different speeds? Is this because the time components are estimated across all variables and might be mis-specified if we have different time scales? This seems counter my current understanding of the core array (i.e., interactions between the components) where time components could interact with variable components.\\
  Long story short: Maybe we can discuss this issue again, I feel like I might have misunderstood something somewhere :-D\\
  Sorry...
  \color{black}
}}

3. **Multiple Imputation.** We then create 20 imputed datasets to perform the analyses on. As outlined by @Monden2015, we will use the key variables themself as well as auxiliary variables to impute missing values. Auxiliary variables are any pre-, post-, or daily dairy variables that are significantly ($p$ < .01) and meaningfully ($r$ > .3) correlated with (1) the key variables or (2) missingness on the key variables.
4. **Three-way ANOVA.** We assess the percentages of explained variance for the person-, variable-, and time aspects --- which offers an indication of whether a 3MPCA is useful for the dataset. Based on the grand mean centered variables we conduct a fixed-effects three-way ANOVA of the person-, variable-, and time modes as well as their various interactions. We are particularly interested in the highest order interaction term Person * Variable * Time + error, as a large amount of variance in this effect would speak towards the interdependence of the three modes.
5. **Data preprocessing.** For the \change{three mode }{3M}PCA, we center (across participants but within time point) and normalize (within variable but across time points) all key variables. The between-person centering, ensures that all variations are around the mean trend (which is removed by the centering). The normalization within variable are important for ensuring equal variances across variables, which ensures equal weighting of the variables in the 3MPCA. For methodological detail see [Transformations].
6. **Selection of 3MPCA model complexity** We then run the 3MPCA. We use a generalized scree plot to select the appropriate number of components for each of the three modes (i.e., person, variable, time). To test the stability of the solution results are compared across the 20 imputed datasets \add{and split-half stability is assessed}.
7. **3MPCA model fitting.** For the selected complexities we then extract simple component structures (i.e., for each mode individually) as well as the \change{array core}{core array} (the full 3MPCA array, which \change{holds the weights of all combinations of the three modes}{specifies all combinations of the three mode components}). A Joint Orthomax orthogonal rotation and standard weights \remove{(when necessary)} are used to extract human interpretable component scores. This procedure is done on all 20 imputed data sets.
8. **Generalized Procrustes rotation.** In order to combine the three individual component structure from the 20 data sets, we use a generalized Procrustes rotation --- calculating the average of each compontent and core array.
9. **Explained variance.** As fit indices we then calculate (1) fit percentage of the estimated array for each imputed data set (i.e., explained variance around the removed general trend) as well as (2) an _overall_ fit percentage of the estimated array (i.e., explained variance including the general trend). Both these fit metrices should give an indication of how much of the original variance the reduced component structure was able to capture.
10. **Component interpretation** To embed and interpret the resulting components (especially the person components), we calculate correlations of the component scores with key adaptation markers (including, well-being, anxiety, trust, or societal inclusion). If components remain unclear still we can additionally perform k-means clustering on the lower dimensional space to identify clearer groups, which can be compared on the adaptation markers if necessary.

## Transformations
<!-- If you plan on transforming, centering, recoding the data, or will require a coding scheme for categorical variables, please describe that process. If any categorical predictors are included in a regression, indicate how those variables will be coded (e.g. dummy coding, summation coding, etc.) and what the reference category will be.

Example: The "Effect of sugar on brownie tastiness" does not require any additional transformations. However, if it were using a regression analysis and each level of sweet had been categorically described (e.g. not sweet, somewhat sweet, sweet, and very sweet), 'sweet' could be dummy coded with 'not sweet' as the reference category. -->

<!-- We will mean-center all level-one predictors within participants (i.e., cluster mean centering). This is relevant for any predictor variable during the interaction (e.g., key need fulfillment, interaction quality, ...). We mean-center within-person predictors, to meaningfully distinguish within and between person variances and because we obtain a meaningful intercept when having a random slope model [e.g., @Hamaker2014]. -->

\setlength{\abovedisplayskip}{0pt}
\setlength{\belowdisplayskip}{0pt}
\setlength{\abovedisplayshortskip}{0pt}
\setlength{\belowdisplayshortskip}{0pt}

For three-mode PCA it is custom to center (across participants but within time point) and to normalize (within variable but across time points). This is done to create a meaningful zero value for each time point (to compare participants) and a variance of 1 across all time points of a variable (ensuring equal weightin of variables in the 3MPCA).

We provide the main equations of the procedure below, where individual $i$ ($i = 1,\ ...,\ I$) reported variable\change{ $k$ ($k = 1,\ ...,\ K$)}{ $x$ and its naturalized form $z$ (where $[k = 1,\ ...,\ K]$ indexes all available variables)} at time point $t$ ($t = 1,\ ...,\ T$), so that $I$=number of persons, $K$=number of items, $T$=number of time points within the dataset. For further information as well as an example illustration see Supplemental Material 3 in @Monden2015.

\begin{equation} \label{eq:Mean}
  \overline{x}_{kt} =  \sum_{i=1}^I x_{ikt}
\end{equation}

\begin{equation} \label{eq:NormalizationSd}
  \sigma_{k} =  \sqrt{\sum_{i=1}^I \sum_{k=1}^K \frac{(x_{ikt}-\overline{x}_{kt})^2}{I*T}}
\end{equation}

\begin{equation} \label{eq:NormalizedScore}
  z_{ikt} =  \frac{x_{ikt}-\overline{x}_{kt}}{\sigma_{k}}
\end{equation}


## Inference criteria
<!-- What criteria will you use to make inferences? Please describe the information youÍll use (e.g. p-values, bayes factors, specific model fit indices), as well as cut-off criterion, where appropriate. Will you be using one or two tailed tests for each of your analyses? If you are comparing multiple conditions or testing multiple hypotheses, will you account for this?

p-values, confidence intervals, and effect sizes are standard means for making an inference, and any level is acceptable, though some criteria must be specified in this or previous fields. Bayesian analyses should specify a Bayes factor or a credible interval. If you are selecting models, then how will you determine the relative quality of each? In regards to multiple comparisons, this is a question with few "wrong" answers. In other words, transparency is more important than any specific method of controlling the false discovery rate or false error rate. One may state an intention to report all tests conducted or one may conduct a specific correction procedure; either strategy is acceptable.

Example: We will use the standard p<.05 criteria for determining if the ANOVA and the post hoc test suggest that the results are significantly different from those expected if the null hypothesis were correct. The post-hoc Tukey-Kramer test adjusts for multiple comparisons. -->

Many of the proposed procedures are descriptive rather then inferential. Importantly, we will use amounts of variances explained as our main fit indices. 
If we perform inferential analyses, we will use the standard p<.05 criteria for determining whether the correlation and regression coefficients are statistically significant. \add{We will use appropriate multiple-comparison corrections whenever multiple tests are performed.} We will place particular emphasis on effect sizes \add{(e.g., correlations) }in our interpretations of the results wherever \change{necessary}{possible}.

## Data exclusion
<!-- How will you determine what data or samples, if any, to exclude from your analyses? How will outliers be handled? Will you use any awareness check? Any rule for excluding a particular set of data is acceptable. One may describe rules for excluding a participant or for identifying outlier data.

Example: No checks will be performed to determine eligibility for inclusion besides verification that each subject answered each of the three tastiness indices. Outliers will be included in the analysis. -->

No checks will be performed to determine eligibility for inclusion besides verification that each subject answered each of the variables of interest for a given analysis. Outliers will generally be included in analyses, however we will use sensitivity analyses to assess the robustness of the results to outliers.  


## Missing data
<!-- How will you deal with incomplete or missing data? Any relevant explanation is acceptable. As a final reminder, remember that the final analysis must follow the specified plan, and deviations must be either strongly justified or included as a separate, exploratory analysis.

Example: If a subject does not complete any of the three indices of tastiness, that subject will not be included in the analysis. -->

The sample selection based on proportions of missing data and the multiple imputation procedures are described in [Statistical models].  


## Exploratory analyses (optional)
<!-- If you plan to explore your data set to look for unexpected differences or relationships, you may describe those tests here. An exploratory test is any test where a prediction is not made up front, or there are multiple possible tests that you are going to use. A statistically significant finding in an exploratory test is a great way to form a new confirmatory hypothesis, which could be registered at a later time.

Example: We expect that certain demographic traits may be related to taste preferences. Therefore, we will look for relationships between demographic variables (age, gender, income, and marital status) and the primary outcome measures of taste preferences. -->


A recent alternative for trajectory dimension reduction has been the use of LSTM auto encoders. The encoder decoder classification procedure has the advantage of being extremely flexible in the use of the data set and could be interpreted in a similar way as the 3MPCA (see [Statistical models] 9).


# Other

## Other (Optional)
<!-- If there is any additional information that you feel needs to be included in your preregistration, please enter it here. Literature cited, disclosures of any related work such as replications or work that uses the same data, or other context that will be helpful for future readers would be appropriate here. -->

Not applicable.

## 
\vspace{-2pc}
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{-1in}
\setlength{\parskip}{8pt}
\noindent
