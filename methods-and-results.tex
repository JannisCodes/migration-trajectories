\subsection{Data}

We used a data set following migration experiences collected by
\citet[][]{Kreienkamp2022b}. The data set consists of three studies that
followed migrants who had recently arrived in the Netherlands in their
daily interactions with the Dutch majority group members. After a
general migration-focused pre-questionnaire, participants were invited
twice per day to report on their (potential) interactions with majority
group members for at least 30 days. The short ESM surveys were sent out
at around lunch (12pm) and dinner time (7pm). After the 30 day study
period participants filled in a post-questionnaire that mirrored the
pre-questionnaire. Participants received either monetary compensation or
partial course credits based on the number of surveys they completed.
For our empirical example we focus on the variables that were collected
during the ESM surveys and were available in all three studies. Full
methodological details are available in the empirical article by
\citet[][]{Kreienkamp2022b}.

\subsubsection{Sample}

The original studies included 207 participants (\(N_{S1}=\) 23,
\(N_{S2}=\) 113, \(N_{S3}=\) 71) with a total of 10,297 measurements.
The studies differed substantially in the maximum length of
participation (\(\text{max}(t_{S1})=\) 63, \(\text{max}(t_{S2})=\) 69,
\(\text{max}(t_{S3})=\) 155). This was likely due to the option to
continue participation without compensation in the later two studies. To
make the three studies comparable in participation and time frames, we
iteratively removed all measurement occasions and participants that had
more than 45\% missingness
\citep[which was in line with the general rcecommendation for data that might still need to rely on imputations for later model testing][]{Madley-Dowd2019}.
This procedure let to a final sample of 157 participants, who jointly
produced 8,132 measurements. Importantly, both the participant
repsonse-patterns and the time frame were now a lot more comparable
(\(\text{max}(t_{S1})=\) 61, \(\text{max}(t_{S2})=\) 60,
\(\text{max}(t_{S3})=\) 67). For a full overview of the data reduction
procedure and study-specific exclusions see Online Supplemental Material
A.

\subsubsection{Variables}

Included 12 variables that were available across all three studies and
captured information about the participant's interactions, as well as
cognitive-, emotional-, and motivational self in relationship with the
majority group. We chose these two aspects in particular because (1) the
interaction-specific information exemplified the structural missingness
issue of modern ESM data and (2) the motivational, emotional, and
cognitive experience offered a diverse conceptualization of migration
experience (beyond behavioral measurements) that is becoming more common
in the literature \citep[][]{Kreienkamp2022d}. Full methodological
details are available in Online Supplemental Material A, but basic item
information, descriptives, and correlations are available in
\tblref{tab:descrWide}.

\subsection{Analysis and Results}

To perform the main analysis on our selected variables, we follow the
three extract--reduce--cluster steps in sequential order. For each of
the steps fully reproducible and annotated code is available in Online
Supplemental A as well as in the accompanying OSF- and GitHub
repositories (REFERENCES).

\subsubsection{Feature extraction}

For the features, we selected and extracted one of each of the features
proposed in \tblref{tab:esmFeatures}. We particularly chose the more
robust median and median absolute deviation (MAD) for central tendency
and variability. Within the variability structure, we chose the slightly
more intuitive mean absolute change (MAC) for stability and stayed with
the common lag--1 autocorrelation for inertia. For the trend summaries,
we chose the overall linear regression slope to describe the linear
trend and we summarized the nonlinear trend with the estimated degrees
of freedom of an empty GAM spline model (edf) --- the edf summarizes the
\textit{wiggliness} of the spline trend line. We chose these features in
particular because we consider them to be the most broadly applicable
features. We also extracted the participant's number of completed ESM
measurements to ensure that the clusters are comparable in that regard.
We include a function that automatically extracts and prepares all
features we extracted as well as a large selection of the time series
feature operationalizations presented in \tblref{tab:esmFeatures} in our
GitHub repository (see the \texttt{featureExtractor} function).

After the feature extraction, we found that about 1.40\% of the
extracted features are missing across participants across the 72
features per participant. This might, for example, happen if
participants do not have two subsequent measurements with outgroup
interactions, so that an autocorrelation with lag-1 cannot be calculated
for the contact-specific variables. The small number of missing values
indicates that the feature-based approach indeed largely avoids the
structural missingness issue. The few missing values can however be an
issue for some feature reduction or feature clustering algorithms. We,
thus, impute the missing feature values with a single predictive mean
matching imputation using the MICE library.

\subsubsection{Feature reduction}

For the feature reduction, we chose the very general
\textit{principal component analysis} (PCA). While some of the more
tailor-made feature selection algorithms can be more accurate and
meaningful in reducing the feature dimensionality, PCAs are
well-established and can broadly be applied in an automatize manner.
80\% rule of thumb

we select the first 27 principal components because they explain 80\% of
the variance in the original 72 features (reducing the dimensions by
62.50\%).

\subsubsection{Feature clustering}

feature engineering: feature extraction + feature selection

use domain knowledge to extract new variables from raw data (summarize)

options: tsfresh \citep[][]{christ2018}

\textit{k} features means \(2^k â€“ 1\) possible models

maximize relevance and minimize redundancy
