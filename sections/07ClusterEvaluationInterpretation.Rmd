---
output: latex_fragment
bibliography: ../referencesZotero.bib
csl: ../apa.csl
---

```{r}
#| label: section setup
#| include: false

# Global Chunk Options
knitr::opts_chunk$set(
  fig.width = 12,
  fig.height = 8,
  fig.path = "../figures/",
  include = FALSE,
  warning = FALSE,
  message = FALSE
)
```

```{r}
#| label: average feature by cluster

# CLUSTER VARIABLE LABELS
variableLab <- c(
  "AttitudesDutch" = "Outgroup Attitude",
  "AttitudesPartner" = "Int: Partner Attitude",
  "DaytimeNeedFulfillment" = "Need Fulfillment",
  "exWB" = "Well-Being",
  "InteractionContextAccidental" = "Int: Accidental",
  "InteractionContextCooperative" = "Int: Cooperative",
  "InteractionContextRepresentativeNL" = "Int: Representative",
  "InteractionContextvoluntary" = "Int: Voluntary",
  "KeyNeedDueToPartner" = "Int: Need Fulfillment Partner",
  "KeyNeedFulfillment" = "Int: Need Fulfillment",
  "qualityMeaning" = "Int: Meaningful",
  "qualityOverall" = "Int: Quality"
) %>% enframe(., name = "variable", value = "label")

# ADD VALIDATION VARS:
validationNam <- c(
  "gender.pre",
  "IntGrAnx01.pre",
  "IntGrAnx02.pre",
  "IntGrAnx03.pre",
  "IntGrAnx04.pre",
  "IntGrAnx05.pre",
  "IntGrAnx06.pre",
  "IntGrAnx07R.pre",
  "IntGrAnx08R.pre",
  "IntGrAnx09R.pre",
  "IntGrAnx10R.pre",
  "IntGrAnx11R.pre",
  "IntGrAnx12R.pre",
  "SWL01.pre",
  "SWL02.pre",
  "SWL03.pre",
  "SWL04.pre",
  "SWL05.pre",
  "EvDayDiscr01.post",
  "EvDayDiscr02.post",
  "EvDayDiscr03.post",
  "EvDayDiscr04.post",
  "EvDayDiscr05.post",
  "EvDayDiscr06.post",
  "EvDayDiscr07.post",
  "EvDayDiscr08.post",
  "EvDayDiscr09.post"
)

# EXTRACT OUT-OF-CLUSTER VALIDATION VARIABLES
dt_raw <- readRDS(file="tutorial/data/osf_mini.Rda")
missingness_ooc <- full_join(
  featData %>%
    group_by(study, PID) %>%
    summarise(n_feature = n()) %>%
    ungroup(),
  dt_raw %>%
    group_by(study, PID) %>%
    summarise(n_raw = n()) %>%
    ungroup(),
  by = c("study", "PID")
) %>%
  mutate(
    nrm = n_raw - n_feature
  ) %>%
  filter(
    !is.na(n_feature)
  ) %>%
  mutate(nrm.z = as.numeric(scale(nrm))) %>%
  select(study, PID, nrm.z)

validation <- rbind(
  dtS1Red %>% select(any_of(idVars), any_of(validationNam)) %>% mutate(study = "S1", gender.pre = (gender.pre-2)*-1),
  dtS2Red %>% select(any_of(idVars), any_of(validationNam)) %>% mutate(study = "S2"),
  dtS3Red %>% select(any_of(idVars), any_of(validationNam)) %>% mutate(study = "S3")
) %>% 
  left_join(., missingness_ooc, by = c("study", "PID")) %>%
  group_by(study, PID) %>%
  mutate(ID = cur_group_id()) %>%
  ungroup %>%
  group_by(study, ID) %>%
  summarise(
    gender = gender.pre,
    nrm.z = nrm.z,
    IntGrAnx.pre = rowMeans(across(starts_with("IntGrAnx")), na.rm = TRUE),
    SWL.pre = rowMeans(across(starts_with("SWL")), na.rm = TRUE),
    EvDayDiscr.post = rowMeans(across(starts_with("EvDayDiscr")), na.rm = TRUE)
  ) %>%
  ungroup %>%
  distinct %>% 
  mutate(
    gender.z = scale(gender, scale = TRUE),
    IntGrAnx.pre.z = scale(IntGrAnx.pre, scale = TRUE),
    SWL.pre.z = scale(SWL.pre, scale = TRUE),
    EvDayDiscr.post.z = scale(EvDayDiscr.post, scale = TRUE)
  ) %>%
  select(
    ID,
    #gender.z,
    #IntGrAnx.pre.z,
    #SWL.pre.z,
    EvDayDiscr.post.z,
    nrm.z
  )
val <- validation %>% select(-ID) %>% names
validationFeature <- validation
for(feature in variableLab$variable) {
  validationFeature <- validationFeature %>% bind_cols(., select(., setNames(val, paste(feature, val, sep = "_"))))
}
validationFeature <- validationFeature %>% select(-any_of(val))


# CLUSTER VARIABLE LABELS
variableLab <- c(
  "AttitudesDutch" = "Outgroup Attitude",
  "AttitudesPartner" = "Int: Partner Attitude",
  "DaytimeNeedFulfillment" = "Need Fulfillment",
  "exWB" = "Well-Being",
  "InteractionContextAccidental" = "Int: Accidental",
  "InteractionContextCooperative" = "Int: Cooperative",
  "InteractionContextRepresentativeNL" = "Int: Representative",
  "InteractionContextvoluntary" = "Int: Voluntary",
  "KeyNeedDueToPartner" = "Int: Need Fulfillment Partner",
  "KeyNeedFulfillment" = "Int: Need Fulfillment",
  "qualityMeaning" = "Int: Meaningful",
  "qualityOverall" = "Int: Quality"
) %>% enframe(., name = "variable", value = "label")
validationLab <- c(
  "gender.z" = "Val: Gender",
  "SWL.pre.z" = "Val: Sat. with life",
  "IntGrAnx.pre.z" = "Val: Intergroup Anxiety",
  "EvDayDiscr.post.z" = " Discrimination"
) %>% enframe(., name = "variable", value = "label")

featCluster <- data.frame(ID = as.numeric(names(kmeansOut$cluster)), cluster = kmeansOut$cluster) %>%
  merge(., z_data) %>%
  group_by(cluster) %>%
  summarise(across(everything(), list(mean = mean, se = se), na.rm=TRUE)) %>%
  ungroup %>% 
  select(-starts_with("ID")) %>%
  pivot_longer(
    cols = -c(cluster),
    names_to = c("variable", ".value"),
    names_pattern = "(.*)_(.*)"
  ) %>% 
  mutate(
    nam = variable,
    variable = gsub("\\_.*", "", nam),
    feature = gsub("^.*?\\_", "", nam)
  ) %>% 
  merge(., variableLab) %>%
  select(
    cluster,
    nam,
    variable,
    label,
    feature,
    everything()
  )

featClusterVal <- data.frame(ID = as.numeric(names(kmeansOut$cluster)), cluster = kmeansOut$cluster) %>%
  merge(., z_data) %>%
  merge(., validationFeature) %>%
  group_by(cluster) %>%
  summarise(across(everything(), list(mean = mean, se = se), na.rm=TRUE)) %>%
  ungroup %>% 
  select(-starts_with("ID")) %>%
  pivot_longer(
    cols = -c(cluster),
    names_to = c("variable", ".value"),
    names_pattern = "(.*)_(.*)"
  ) %>% 
  mutate(
    nam = variable,
    variable = gsub("\\_.*", "", nam),
    feature = gsub("^.*?\\_", "", nam)
  ) %>% 
  merge(., variableLab) %>% 
  mutate(feature = stri_replace_all_regex(
    feature,
    pattern=validationLab$variable,
    replacement=validationLab$label,
    vectorize=FALSE
  )) %>% 
  select(
    cluster,
    nam,
    variable,
    label,
    feature,
    everything()
  )

rawCluster <- data.frame(ID = as.numeric(names(kmeansOut$cluster)), cluster = kmeansOut$cluster) %>%
  merge(., raw_data) %>%
  select(
    ID,
    TIDnum,
    cluster,
    any_of(varNamS123)
  ) %>%
  reshape2::melt(id.vars = c("cluster", "ID","TIDnum")) %>% 
  merge(., variableLab)
```

```{r}
#| label: formal cluster comparison
#| echo: false

raw_feat_clust <- data.frame(ID = as.numeric(names(kmeansOut$cluster)), cluster = kmeansOut$cluster) %>%
  merge(., z_data) %>%
  merge(., validationFeature) 

concepts_and_feature <- str_match(colnames(raw_feat_clust), "(.*)_(.*)")
concepts <- na.omit(unique(concepts_and_feature[, 2]))
ts_features <- na.omit(unique(concepts_and_feature[, 3]))


feat_t_test <- function(df, cluster_var, concept, ts_feature) {
  column_name <- paste0(concept, "_", ts_feature)
  
  group1 <- df[df[[cluster_var]] == unique(df[[cluster_var]])[1], column_name]
  group2 <- df[df[[cluster_var]] == unique(df[[cluster_var]])[2], column_name]
  
  t.test(group1, group2)
}

results <- list()
for (feature in ts_features) {
  for (concept in concepts) {
    results[[feature]][[concept]] <- feat_t_test(raw_feat_clust, "cluster", concept, feature)
  }
}

results_df <- data.frame(concept = character(),
                         feature = character(),
                         difference = numeric(),
                         df = numeric(),
                         t_value = numeric(),
                         p_value = numeric(),
                         lwr = numeric(),
                         upr = numeric(),
                         stringsAsFactors = FALSE)

for (feature in ts_features) {
  for (concept in concepts) {
    # Run t-test
    test_result <- results[[feature]][[concept]]
    
    # Extract required values from t-test result
    difference <- test_result$estimate[1] - test_result$estimate[2]  # difference between group means
    t_value <- test_result$statistic  # t-value
    df <- test_result$parameter  # df
    p_value <- test_result$p.value  # p-value
    lwr <- test_result$conf.int[1] # lower CI
    upr <- test_result$conf.int[2] # upper CI

    # Add a row to the results dataframe
    results_df <- rbind(results_df, data.frame(concept = concept,
                                               feature = feature,
                                               difference = difference,
                                               t_value = t_value,
                                               df = df,
                                               p_value = p_value,
                                               lwr = lwr,
                                               upr = upr,
                                               stringsAsFactors = FALSE))
  }
}

results_df <- results_df %>%
      mutate(
        star = ifelse(p_value < 0.001, "***", ifelse(p_value < 0.01, "**", ifelse(p_value < 0.05, "*", "")))
      ) %>% 
 left_join(
   variableLab,
   by = c('concept' = 'variable')
 )
  

feature_plot_list <- list()
for (feature in unique(results_df$feature)) {
  # Subset the data for the current feature
  feature_data <- results_df[results_df$feature == feature, ]
  
  df_plot <- data.frame(label = feature_data$label,
                        difference = feature_data$difference,
                        lwr = feature_data$lwr,
                        upr = feature_data$upr)
  
  feature_plot_list[[feature]] <- ggplot(df_plot, aes(y = label)) +
    geom_point(aes(x = difference), shape=15, size=2) +
    geom_linerange(aes(xmin = lwr, xmax = upr)) +
    geom_vline(xintercept = 0, linetype="dashed") +
    scale_x_continuous(expand = expansion(mult = 0)) +
    theme_Publication() + 
    theme(panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank(), 
          axis.text.y = element_text(hjust=0), 
          axis.line.y = element_blank(),
          axis.ticks.y = element_blank(),
          axis.title.y = element_blank())
}


plot_feature_selection <- c(
  "median",
  "mad",
  "lin",
  "edf"
)
feature_limits <- results_df %>%
  filter(feature %in% plot_feature_selection) %>% 
  summarise(
    min_lwr = min(lwr, na.rm = TRUE),
    max_upr = max(upr, na.rm = TRUE)
  ) %>%
  as.numeric()

feature_comparison_combined <-
  ggpubr::ggarrange(
    feature_plot_list$median +
      scale_x_continuous(limits = feature_limits) +
      theme(
        axis.title.x = element_blank(),
        plot.margin = margin(
          t = 20,
          r = 1,
          b = 20,
          l = 20
        )
      ),
    feature_plot_list$mad +
      scale_x_continuous(limits = feature_limits) +
      theme(
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        plot.margin = margin(
          t = 20,
          r = 20,
          b = 20,
          l = 20
        )
      ),
    feature_plot_list$lin +
      scale_x_continuous(limits = feature_limits) +
      theme(# aspect.ratio = 1,
        plot.margin = margin(
          t = 20,
          r = 1,
          b = 10,
          l = 20
        )),
    feature_plot_list$edf +
      scale_x_continuous(limits = feature_limits) +
      theme(
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        plot.margin = margin(
          t = 20,
          r = 20,
          b = 10,
          l = 20
        )
      ),
    ncol = 2,
    nrow = 2,
    widths = c(1.325, 1),
    # align = "hv",
    labels = c("(A) Median", "(B) MAD", "(C) Linear Slope", "(D) GAM edf"),
    hjust = c(-0.25, -0.27, -0.17, -0.22),
    common.legend = TRUE,
    legend = "bottom"
  ) 
ggsave("Figures/feature_comparison_combined.pdf", feature_comparison_combined, width = 12, height = 12)

# Check if any graphics devices are open
if (length(dev.list()) > 0) {
  # Close the graphics device
  dev.off()
}
pdf("figures/feature_comparison_mad.pdf")
feature_plot_list$mad
dev.off()
png("figures/feature_comparison_mad.png")
feature_plot_list$mad
dev.off()

feat_ttest_apa <- function(results_df, concept_in, feature_in) {
  # concept_in <- "InteractionContextvoluntary"
  # feature_in  <- "median"
  
  diff <- results_df %>% 
    filter(concept == concept_in, feature == feature_in) %>% 
    select(difference) %>% 
    pull %>% 
    round(., 2) %>% 
    format(., nsmall=2)
  t <- results_df %>% 
    filter(concept == concept_in, feature == feature_in) %>% 
    select(t_value) %>% 
    pull %>% 
    round(., 2) %>% 
    format(., nsmall=2)
  df <- results_df %>% 
    filter(concept == concept_in, feature == feature_in) %>% 
    select(df) %>% 
    pull %>% 
    round(., 2) %>%
    format(., nsmall=2)
  p <- results_df %>% 
    filter(concept == concept_in, feature == feature_in) %>% 
    select(p_value) %>% 
    pull
  p <- ifelse(p < 0.001, "< .001", 
              paste0("= ", format(round(p, 3), nsmall=3)))
  lwr <- results_df %>% 
    filter(concept == concept_in, feature == feature_in) %>% 
    select(lwr) %>% 
    pull %>% 
    round(., 2) %>%
    format(., nsmall=2)
  upr <- results_df %>% 
    filter(concept == concept_in, feature == feature_in) %>% 
    select(upr) %>% 
    pull %>% 
    round(., 2) %>%
    format(., nsmall=2)
  
  paste("\\textit{difference} = ", diff,
        ", $t$(", df, ") = ", t,
        ", $p$ ", p , 
        ", \\textit{95\\%CI} [", lwr,
        ", ", upr, "]",
        sep = "")
}


```

In short, we find that the feature-based clustering discerned two meaningfully different groups of participants. We find an adaptive group (cluster 1) that reports higher well-being (\textit{median}: `r feat_ttest_apa(results_df, "exWB", "median")`; also see \fgrref[A]{fig:cluster_comparison_features}) and more positive outgroup interactions (\textit{median}: `r feat_ttest_apa(results_df, "qualityOverall", "median")`), which are also stable over time (\textit{MAC}: `r feat_ttest_apa(results_df, "qualityOverall", "mac")`) and tend to increase more over the 30 day test period (\textit{linear trend}: `r feat_ttest_apa(results_df, "qualityOverall", "lin")`; also see \fgrref[C]{fig:cluster_comparison_features}). This group also reported consistently more meaningful (\textit{median}: `r feat_ttest_apa(results_df, "qualityMeaning", "median")`), need-fulfilling (\textit{median}: `r feat_ttest_apa(results_df, "KeyNeedFulfillment", "median")`), and cooperative outgroup interactions (\textit{median}: `r feat_ttest_apa(results_df, "InteractionContextCooperative", "median")`). This group with overwhelmingly positive experiences stands in contrast with a more detrimental group (cluster 2). This cluster, on average, reported much less positive, less meaningful, and less fulfilling interactions and interaction patterns (\textit{median}). This group also reported less positive outgroup attitudes, lower well-being, and more discrimination experiences (\textit{median}). At the same time, for members of this detrimental cluster (cluster 2) conditions seemed to deteriorate over time (\textit{linear trend}), and there was generally less consistency in the experiences they were able to have (\textit{MAC}, \textit{MAD}, \textit{edf}; also see \fgrref[]{fig:cluster_comparison_features}; for a full and interactive comparison of all features see \situtorial). 

To identify these patterns, we first inspect the clusters based on the average values of meaningful features (see \fgrref[A]{fig:clusterFeatVar}; \citealp{Kennedy2021}). We see that for some variables the features are generally stronger in separating the clusters. We, for example, see that the item on '\textit{how cooperative the interaction was}' distinguishes the two clusters across almost all seven features (except for the \textit{auto-correlation}, see \fgrref[A]{fig:clusterFeatVar}). Compare this to the '\textit{outgroup attitudes}' item where the differences between the clusters are much smaller for almost all features. We then inspect the clusters with a focus on the features (see \fgrref[B]{fig:clusterFeatVar}). While this is the same data as for the variable focus, we can see more clearly that some features are better at distinguishing the clusters across variables. For example, \textit{MAD} and \textit{median} distinguish the two clusters across almost all variables (except for the item of whether the interaction was representative of the outgroup). These two features stand in stark contrast to other features, such as the \textit{lag-1 auto correlations} or the \textit{GAM edf}, which showed much smaller differences between the two clusters (see \fgrref[B]{fig:clusterFeatVar} and \fgrref[]{fig:cluster_comparison_features}; please note that we offer readers an interactive tool to assess the cluster differences for all features in \situtorial). This offers some information on which features were most important in differentiating the two extracted groups but also shows that with real-world data, not all features will have enough range to distinguish people on all variables (e.g., see the non-linearity patterns in \fgrref[]{fig:cluster_comparison_features}; for a more direct illustration of GAM edf differences see \citealp{bringmann2017}). Taking these two perspectives together, we can also focus on individual features or variables in particular. We, for example, see a strong difference in the average well-being, where participants in cluster 2 showed a much lower median well-being over the time series (`r feat_ttest_apa(results_df, "exWB", "median")`). At the same time, in terms of well-being stability, both groups have virtually identical average \textit{MAC} statistics for well-being (`r feat_ttest_apa(results_df, "exWB", "mac")`; also see \fgrref[A]{fig:clusterFeatVar}). There are, thus, variables and features that distinguish the clusters better than others and a combination of variables and features lets us explore meaningful group differences in more detail. In our case, we see that the central tendency, variability, and linear trend are best at distinguishing a group with mainly positive experiences (cluster 1) from a group with a more negative experience (cluster 2). We also see that our clusters line up with the past literature on the importance of focusing on simpler and more meaningful statistics \citep{bringmann2018c, eronen2021a, dejonckheere2019}.

```{=tex}
\begin{figure}[!ht] %hbtp
  \caption{Cluster Group Comparisons based on Features and Variables}
  \label{fig:clusterFeatVar}
  \centering\includegraphics[width=\textwidth]{figures/clusterFeatVarComb_tutorial.pdf}
  \caption*{Note: \\
  "Int." = outgroup interaction, "mad" = median absolute deviation, "mac" = mean absolute change, "lin" = linear slope, "edf" = estimated degrees of freedom of an empty GAM spline model, "ar01" = lag-1 autocorrelation, "OCC"/"occ" = out-of-cluster comparison\\
  Within the "(B) Feature Focus" subplot, the 'n (within ooc)' is an out-of-cluster comparison of the within-person available measurements for each variable; the 'between ooc (mean)' are also out-of-cluster comparisons but on a between person level. 'Measurements removed' is the person-specific count of measurement occasions removed during the missingness handling and 'Discrimination' is the scale mean of daily discimination experiences (measured during the final survey).}
\end{figure}
```

In the second step, we look at the prototypical trajectories of the clusters. For k-means clustering it is often recommended to use the average over time of the responses within the cluster \citep[see \fgrref{fig:clusterTs};][]{niennattrakul2007}\footnote{It is important to note, however, that direct comparability can be a concern, and often times some subset selection or nonlinear alignment is necessary \citep[e.g.,][]{gupta1996}.}. Immediately striking are the mean differences, where participants in cluster 1 had more meaningful and fulfilling outgroup interactions and also consistently reported more voluntary and cooperative interactions but fewer accidental and involuntary interactions. The same cluster (cluster 1) also reported an increase in need-fulfilling interactions over the 30-day period and an increase in interactions that were representative of the outgroup. Whereas the other cluster (cluster 2) showed a decrease in voluntary, cooperative, and positive interactions over the 30 days. This `deterioration' cluster (cluster 2) also saw a decrease in general need fulfillment but not experienced well-being over the 30 days (see \fgrref[C]{fig:cluster_comparison_features}). We also see that while interaction representativeness, outgroup attitudes, and well-being are relatively stable for both clusters, the deteriorating cluster (cluster 2) also showed substantially higher variability and instability on most of the other variables (although these effects are much smaller; see \fgrref[A]{fig:clusterTs}).

Finally, we can also assess the clusters across other individual difference variables \citep[e.g.,][]{monden2022}. This out-of-feature comparison allows us to check for data artifacts, as well as check whether the developmental clusters are associated with important social markers and individual differences. To illustrate artifact checks, we added the number of ESM measurements into the comparison and find that the participants in the deterioration cluster (cluster 2) on average completed slightly more ESM surveys in general and reported on more intergroup interactions in particular (see $n$ in \fgrref[B]{fig:clusterFeatVar}). In our data exclusion procedures, we ensured that the general time frame and completion rates are similar for all participants and indeed the numbers in ESM measurements generally are largely similar (e.g., see $n$ for well-being and outgroup attitudes). However, the difference in the reported number of interactions might indicate either a clustering artifact or a meaningful difference. The higher average number of interactions in cluster 2 could, for example, indicate a clustering artifact if variances are substantially larger due to the larger samples \citep[e.g., restriction of range in the smaller sample][]{kogan2006}. In our case, this seems less likely because one out of four variables did not differ in terms of the MAD (i.e., our selected measurement of the time series variance; see \fgrref{fig:cluster_comparison_features} for an illustration). At the same time, however, the difference in the number of experienced interactions might also indicate a meaningful difference, where the deteriorating cluster (cluster 2) on average reported more outgroup interactions (`r feat_ttest_apa(results_df, "InteractionContextvoluntary", "n")`), but these interactions were less voluntary (`r feat_ttest_apa(results_df, "InteractionContextvoluntary", "median")`), less meaningful (`r feat_ttest_apa(results_df, "qualityMeaning", "median")`), and less positive (`r feat_ttest_apa(results_df, "qualityOverall", "median")`). Thus, while more research is needed for a conclusive test, our data seems to suggest that the differences in reported interactions are a meaningful difference between the clusters. Such a finding would also be in line with past research highlighting the role of negative intergroup interactions in explaining intergroup relations \citep[e.g.,][]{Barlow2012, Prati2021, Graf2014}. A related validity check was the inclusion of the missingness handling, where we compared the two clusters on the average number of measurements removed as part of the missingness handling. We find that the clusters did not significantly differ on this metric suggesting that the missingness handling did not affect the cluster separation (also see \appref[]{app:ValidationAnalyses} and \situtorial).

```{=tex}
\begin{figure}[!ht] %hbtp
  \caption{Comparison Cluster Differences by Features and Variables.}
  \label{fig:cluster_comparison_features}
  \centering\includegraphics[width=\textwidth]{figures/feature_comparison_combined.pdf}
  \caption*{Note:\\
  The figure shows the differences between the clusters in the standardized features that were entered into the dimensionality reduction (for each input variable). We display the median (panel A), the median absolute deviation (MAD, panel B), the univariate linear slope (panel C), as well as the estimated degrees of freedom of the generalized additive model splines (GAM edf, panel D). Please also note that as part of \situtorial, we provide readers with an interactive selection tool to compare cluster differences on all variables and features.}
\end{figure}
```

To further illustrate the utility of assessing out-of-feature individual differences, we also compare the two samples in terms of the participants' self-reported discrimination experiences in the Netherlands (measured during the post-measurement). When looking at the group comparison, we find that participants in the deteriorating cluster (cluster 2) reported substantially higher levels of everyday discrimination (`r feat_ttest_apa(results_df, "exWB", "EvDayDiscr.post.z")`; \fgrref[B]{fig:clusterFeatVar}). Thus, both intensive longitudinal (e.g., the sum of specific ESM measurements) and cross-sectional variables (e.g., general discrimination differences) that were not included in the original clustering step can be used to explore and understand the cluster differences in more detail.

This cluster separation, then, has a number of empirical and practical applications. Firstly, the clusters are descriptive. With tens of variables, hundreds of participants, and thousands of measurements, singular descriptive statistics are often not able to capture the complex patterns that describe the data set. The feature-based clustering offers some direct insight into the complexity within the data set. In our empirical example, we, for example, see that participants are meaningfully distinguished by a combination of high (vs. low) central tendency, variability, and linear trend. Secondly, the clusters identify important groups. The adaptive and deteriorating groups offer starting points for empirical exploration as well as practical interventions. Researchers can start probing what exactly distinguishes the two groups further and generate new bottom-up hypotheses. Practitioners in the resettlement field can use the group separation to identify individuals in need of assistance and can explore contextual factors that might contribute to the difficulties some might face. In our illustration we, for example, found that participants in the deteriorating cluster (cluster 2) reported less need fulfilling interactions over time. Thirdly, the feature-based approach is flexible and meaningful. We were able to use a wide range of time series features that have been central in the ESM literature and were able to use them directly to identify meaningful groups. For our empirical illustration we, among others for example, chose to focus on whether participants differed in their average well-being (i.e., \textit{median}), how much their well-being would vary over time (i.e, \textit{MAD}), and whether their well-being would on average increase or decrease over time (i.e., \textit{linear trend}). Alternatively, for others cyclical patterns might be more important --- for example, whether well-being was higher on weekends. Importantly, in any case, we did not need to translate these dynamic features into probabilistic inference models (e.g., VAR models) to cluster the participants.

```{=tex}
\begin{figure}[!ht] %hbtp
  \caption{Cluster Group Comparisons over time}
  \label{fig:clusterTs}
  \centering\includegraphics[width=\textwidth]{figures/clusterTsComb.pdf}
  \caption*{Note: \\
  Subplot (A) displays the variable cluster means at every measurement occasion. The thinner lines present all individual time series. Subplot (B) shows the GAM spline for each cluster across the measurement occasions. The thinner lines present all individual GAM Splines.}
\end{figure}
```



```{r}
#| label: clusterVariableGrid

clusterVariableGrid <- featCluster %>% 
  filter(feature != "n") %>%
  ggplot(., aes(x = feature, y = mean, group = cluster, color = as.factor(cluster))) +
  geom_point() +
  geom_line() +
  scale_colour_manual(values = c("#384B6B", "#E2892B")) + 
  #geom_errorbar(aes(ymin = mean-se, ymax = mean+se), width=.1, position=position_dodge(0.1), size=0.5, alpha=0.4) +
  coord_flip() +
  labs(
    x = "Features",
    y = "Standardized Mean",
    color = "Cluster"
  ) +
  facet_wrap(~ label) +
  theme_Publication()
clusterVariableGrid
```

```{r}
#| label: clusterFeatureGrid

clusterFeatureGrid <- featClusterVal %>% 
  ggplot(., aes(x = label, y = mean, group = cluster, color = as.factor(cluster))) +
  geom_point() +
  geom_line() +
  #geom_ribbon(aes(ymin = mean-se, ymax = mean+se), alpha = 0.2) +
  #geom_errorbar(aes(ymin = mean-se, ymax = mean+se), width=.1, position=position_dodge(0.1), size=0.5, alpha=0.4) +
  scale_colour_manual(values = c("#384B6B", "#E2892B")) + 
  coord_flip() +
  labs(
    x = "Variable",
    y = "Standardized Mean",
    color = "Cluster"
  ) +
  facet_wrap(~ factor(feature, levels = unique(featClusterVal$feature)), ncol=4) +
  theme_Publication()
clusterFeatureGrid
```

```{r}
#| label: clusterFeatVarComb

clusterFeatVarComb <- ggpubr::ggarrange(
  clusterVariableGrid + theme(axis.title.x = element_blank()),
  clusterFeatureGrid,
  ncol = 1,
  labels = c("(A) Variable Focus", "(B) Feature Focus"),
  common.legend = TRUE,
  legend = "bottom",
  align = "v"
) 
ggsave("Figures/clusterFeatVarComb.pdf", clusterFeatVarComb, width = 12, height = 12)
```

```{r clusterTS, include=FALSE}
clusterTS <- rawCluster %>% 
  ggplot(., aes(x=TIDnum, y=value, group=cluster, color=as.factor(cluster))) +
  geom_line(aes(x=TIDnum, y=value, group=ID, color=as.factor(cluster)), alpha=0.05) +
  stat_summary(fun=mean, geom="line") +
  scale_colour_manual(values = c("#384B6B", "#E2892B")) + 
  facet_wrap(~ label, scales = "free_y") +
  labs(
    x = "Time ID",
    y = "Response (Mean Cluster Response Bold)",
    color = "Cluster"
  ) +
  theme_Publication() 
clusterTS
```

```{r clusterTSTrend, include=FALSE}
clusterTSTrend <- rawCluster %>% 
  ggplot(., aes(x=TIDnum, y=value, group=cluster, color=as.factor(cluster))) +
  geom_line(stat="smooth", method = "gam", aes(group=ID, color=as.factor(cluster)), se = FALSE, alpha=0.1) +
  geom_smooth(aes(group=cluster), method = "gam", se = FALSE) +
  scale_colour_manual(values = c("#384B6B", "#E2892B")) + 
  #stat_summary(fun=mean, geom="line") +
  facet_wrap(~ label, scales = "free_y") +
  labs(
    x = "Time ID",
    y = "Response (Mean Cluster Response Bold)",
    color = "Cluster"
  ) +
  theme_Publication()
clusterTSTrend
```

```{r clusterTsComb, include=FALSE}
clusterTsComb <- ggpubr::ggarrange(
  clusterTS + theme(axis.title.x = element_blank()),
  clusterTSTrend,
  ncol = 1,
  labels = c("(A) Timepoint Means", "(B) Spline Trends"),
  common.legend = TRUE,
  legend = "bottom"
)
ggsave("Figures/clusterTsComb.pdf", clusterTsComb, width = 12, height = 12)
```