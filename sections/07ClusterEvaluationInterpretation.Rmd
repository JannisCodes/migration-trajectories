---
output: latex_fragment
bibliography: ../referencesZotero.bib
csl: ../apa.csl
---

```{r}
#| label: section setup
#| include: false

# Global Chunk Options
knitr::opts_chunk$set(
  fig.width = 12,
  fig.height = 8,
  fig.path = "../figures/",
  include = FALSE,
  warning = FALSE,
  message = FALSE
)
```

```{r}
#| label: average feature by cluster

# CLUSTER VARIABLE LABELS
variableLab <- c(
  "AttitudesDutch" = "Outgroup Attitude",
  "AttitudesPartner" = "Int: Partner Attitude",
  "DaytimeNeedFulfillment" = "Need Fulfillment",
  "exWB" = "Well-Being",
  "InteractionContextAccidental" = "Int: Accidental",
  "InteractionContextCooperative" = "Int: Cooperative",
  "InteractionContextRepresentativeNL" = "Int: Representative",
  "InteractionContextvoluntary" = "Int: Voluntary",
  "KeyNeedDueToPartner" = "Int: Need Fulfillment Partner",
  "KeyNeedFulfillment" = "Int: Need Fulfillment",
  "qualityMeaning" = "Int: Meaningful",
  "qualityOverall" = "Int: Quality"
) %>% enframe(., name = "variable", value = "label")

# ADD VALIDATION VARS:
validationNam <- c(
  "gender.pre",
  "IntGrAnx01.pre",
  "IntGrAnx02.pre",
  "IntGrAnx03.pre",
  "IntGrAnx04.pre",
  "IntGrAnx05.pre",
  "IntGrAnx06.pre",
  "IntGrAnx07R.pre",
  "IntGrAnx08R.pre",
  "IntGrAnx09R.pre",
  "IntGrAnx10R.pre",
  "IntGrAnx11R.pre",
  "IntGrAnx12R.pre",
  "SWL01.pre",
  "SWL02.pre",
  "SWL03.pre",
  "SWL04.pre",
  "SWL05.pre",
  "EvDayDiscr01.post",
  "EvDayDiscr02.post",
  "EvDayDiscr03.post",
  "EvDayDiscr04.post",
  "EvDayDiscr05.post",
  "EvDayDiscr06.post",
  "EvDayDiscr07.post",
  "EvDayDiscr08.post",
  "EvDayDiscr09.post"
)

# EXTRACT OUT-OF-CLUSTER VALIDATION VARIABLES
validation <- rbind(
  dtS1Red %>% select(any_of(idVars), any_of(validationNam)) %>% mutate(study = "S1", gender.pre = (gender.pre-2)*-1),
  dtS2Red %>% select(any_of(idVars), any_of(validationNam)) %>% mutate(study = "S2"),
  dtS3Red %>% select(any_of(idVars), any_of(validationNam)) %>% mutate(study = "S3")
) %>% 
  group_by(study, PID) %>%
  mutate(ID = cur_group_id()) %>%
  ungroup %>%
  group_by(study, ID) %>%
  summarise(
    gender = gender.pre,
    IntGrAnx.pre = rowMeans(across(starts_with("IntGrAnx")), na.rm = TRUE),
    SWL.pre = rowMeans(across(starts_with("SWL")), na.rm = TRUE),
    EvDayDiscr.post = rowMeans(across(starts_with("EvDayDiscr")), na.rm = TRUE)
  ) %>%
  ungroup %>%
  distinct %>% 
  mutate(
    gender.z = scale(gender, scale = TRUE),
    IntGrAnx.pre.z = scale(IntGrAnx.pre, scale = TRUE),
    SWL.pre.z = scale(SWL.pre, scale = TRUE),
    EvDayDiscr.post.z = scale(EvDayDiscr.post, scale = TRUE)
  ) %>%
  select(
    ID,
    #gender.z,
    #IntGrAnx.pre.z,
    #SWL.pre.z,
    EvDayDiscr.post.z
  )
val <- validation %>% select(-ID) %>% names
validationFeature <- validation
for(feature in variableLab$variable) {
  validationFeature <- validationFeature %>% bind_cols(., select(., setNames(val, paste(feature, val, sep = "_"))))
}
validationFeature <- validationFeature %>% select(-any_of(val))


# CLUSTER VARIABLE LABELS
variableLab <- c(
  "AttitudesDutch" = "Outgroup Attitude",
  "AttitudesPartner" = "Int: Partner Attitude",
  "DaytimeNeedFulfillment" = "Need Fulfillment",
  "exWB" = "Well-Being",
  "InteractionContextAccidental" = "Int: Accidental",
  "InteractionContextCooperative" = "Int: Cooperative",
  "InteractionContextRepresentativeNL" = "Int: Representative",
  "InteractionContextvoluntary" = "Int: Voluntary",
  "KeyNeedDueToPartner" = "Int: Need Fulfillment Partner",
  "KeyNeedFulfillment" = "Int: Need Fulfillment",
  "qualityMeaning" = "Int: Meaningful",
  "qualityOverall" = "Int: Quality"
) %>% enframe(., name = "variable", value = "label")
validationLab <- c(
  "gender.z" = "Val: Gender",
  "SWL.pre.z" = "Val: Sat. with life",
  "IntGrAnx.pre.z" = "Val: Intergroup Anxiety",
  "EvDayDiscr.post.z" = " Discrimination"
) %>% enframe(., name = "variable", value = "label")

featCluster <- data.frame(ID = as.numeric(names(kmeansOut$cluster)), cluster = kmeansOut$cluster) %>%
  merge(., z_data) %>%
  group_by(cluster) %>%
  summarise(across(everything(), list(mean = mean, se = se), na.rm=TRUE)) %>%
  ungroup %>% 
  select(-starts_with("ID")) %>%
  pivot_longer(
    cols = -c(cluster),
    names_to = c("variable", ".value"),
    names_pattern = "(.*)_(.*)"
  ) %>% 
  mutate(
    nam = variable,
    variable = gsub("\\_.*", "", nam),
    feature = gsub("^.*?\\_", "", nam)
  ) %>% 
  merge(., variableLab) %>%
  select(
    cluster,
    nam,
    variable,
    label,
    feature,
    everything()
  )

featClusterVal <- data.frame(ID = as.numeric(names(kmeansOut$cluster)), cluster = kmeansOut$cluster) %>%
  merge(., z_data) %>%
  merge(., validationFeature) %>%
  group_by(cluster) %>%
  summarise(across(everything(), list(mean = mean, se = se), na.rm=TRUE)) %>%
  ungroup %>% 
  select(-starts_with("ID")) %>%
  pivot_longer(
    cols = -c(cluster),
    names_to = c("variable", ".value"),
    names_pattern = "(.*)_(.*)"
  ) %>% 
  mutate(
    nam = variable,
    variable = gsub("\\_.*", "", nam),
    feature = gsub("^.*?\\_", "", nam)
  ) %>% 
  merge(., variableLab) %>% 
  mutate(feature = stri_replace_all_regex(
    feature,
    pattern=validationLab$variable,
    replacement=validationLab$label,
    vectorize=FALSE
  )) %>% 
  select(
    cluster,
    nam,
    variable,
    label,
    feature,
    everything()
  )

rawCluster <- data.frame(ID = as.numeric(names(kmeansOut$cluster)), cluster = kmeansOut$cluster) %>%
  merge(., raw_data) %>%
  select(
    ID,
    TIDnum,
    cluster,
    any_of(varNamS123)
  ) %>%
  reshape2::melt(id.vars = c("cluster", "ID","TIDnum")) %>% 
  merge(., variableLab)
```

In short, we find that the feature-based clustering discerned two meaningfully different groups of participants. We find an adaptive group (cluster 1) that reports higher well-being and more positive outgroup attitudes (\textit{median}) that are also stable over time (\textit{MAD}, \textit{MAC}) and tend to increase over the 30 day test period (\textit{linear trend}). This group also reported consistently more meaningful, need-fulfilling, and cooperative outgroup interactions (\textit{median}). This group with overwhelmingly positive experiences stands in contrast with a more detrimental group (cluster 2). This cluster, on average, reported much less positive, less meaningful, and less fulfilling interactions and interaction patterns (\textit{median}). This group also reported less positive outgroup attitudes, lower well-being, and more discrimination experiences (\textit{median}). At the same time, for members of this detrimental cluster (cluster 2) conditions seemed to deteriorate over time (\textit{linear trend}), and there was generally less consistency in the experiences they were able to have (\textit{MAC}, \textit{MAD}, \textit{edf}). 

To identify these patterns, we first inspect the clusters based on the average values of meaningful features (see \fgrref[A]{fig:clusterFeatVar}; \citealp{Kennedy2021}). We see that for some variables the features are generally stronger in separating the clusters. We, for example, see that the item on '\textit{how cooperative the interaction was}' distinguishes the two clusters across almost all seven features (except for the \textit{auto-correlation}, see \fgrref[A]{fig:clusterFeatVar}). Compare this to the '\textit{outgroup attitudes}' item where the differences between the clusters are much smaller for almost all features. We then inspect the clusters with a focus on the features (see \fgrref[B]{fig:clusterFeatVar}). While this is the same data as for the variable focus, we can see more clearly that some features are better at distinguishing the clusters across variables. For example, \textit{MAD} and \textit{median} distinguish the two clusters across almost all variables (except for the item of whether the interaction was representative of the outgroup). These two features stand in stark contrast to other features, such as the \textit{lag-1 auto correlations}, which showed much smaller differences between the two clusters (see \fgrref[B]{fig:clusterFeatVar}). This offers some information on which features were most important in understanding the two extracted groups. Taking these two perspectives together, we can also focus on individual features or variables in particular. We, for example, see a strong difference in the average well-being, where participants in cluster 2 showed a much lower median well-being over the time series. At the same time, in terms of stability, both groups have virtually identical average \textit{MAC} statistics for well-being (see \fgrref[A]{fig:clusterFeatVar}). There are, thus, variables and features that distinguish the clusters better than others and a combination of variables and features lets us explore meaningful group differences in more detail. In our case, we see that the central tendency, variability, and linear trend are best at distinguishing a group with mainly positive experiences (cluster 1) from a group with a more negative experience (cluster 2). We also see that our clusters line up with the past literature on the importance of focusing on simpler and more meaningful statistics \citep{bringmann2018c, eronen2021a}.

```{=tex}
\begin{figure}[!ht] %hbtp
  \caption{Cluster Group Comparisons based on Features and Variables}
  \label{fig:clusterFeatVar}
  \centering\includegraphics[width=\textwidth]{figures/clusterFeatVarComb.pdf}
  \caption*{Note: \\
  "Int." = outgroup interaction. Within the "(B) Feature Focus" subplot, the 'n' and 'Discrimination' comparison variables were not part of the original time series clustering.}
\end{figure}
```

In the second step, we look at the prototypical trajectories of the clusters. For k-means clustering it is often recommended to use the average over time of the responses within the cluster \citep[see \fgrref{fig:clusterTs};][]{niennattrakul2007}\footnote{It is important to note, however, that direct comparability can be a concern, and often times some subset selection or nonlinear alignment is necessary \citep[e.g.,][]{gupta1996}. Additionally, finding cluster prototypes is often substantially easier with embedded clustering methods because in many cases a cluster-level model is estimated as part of the expectation–maximization procedure \citep[e.g.,][]{denteuling2021} or \textit{S-GIMME} \citep[e.g.][]{lane2019}. For medoid-based clustering algorithms, a common approach is simply using cluster medoid as the prototype \citep{kaufman1990}.}. Immediately striking are the mean differences, where participants in cluster 1 had more meaningful and fulfilling outgroup interactions and also consistently reported more voluntary and cooperative interactions but fewer accidental and involuntary interactions. The same cluster (cluster 1) also reported an increase in need-fulfilling interactions over the 30-day period and an increase in interactions that were representative of the outgroup. Whereas the other cluster (cluster 2) showed a decrease in voluntary, cooperative, and positive interactions over the 30 days. This `deterioration' cluster (cluster 2) also saw a decrease in general need fulfillment and experienced well-being over the 30 days (see \fgrref[B]{fig:clusterTs}). We also see that while interaction representativeness, outgroup attitudes, and well-being are relatively stable for both clusters, the deteriorating cluster (cluster 2) also showed substantially higher variability and instability on most of the other variables (also see \fgrref[A]{fig:clusterTs}).

```{r}
#| label: formal cluster comparison
#| echo: false

raw_feat_clust <- data.frame(ID = as.numeric(names(kmeansOut$cluster)), cluster = kmeansOut$cluster) %>%
  merge(., z_data) %>%
  merge(., validationFeature) 

concepts_and_feature <- str_match(colnames(raw_feat_clust), "(.*)_(.*)")
concepts <- na.omit(unique(concepts_and_feature[, 2]))
ts_features <- na.omit(unique(concepts_and_feature[, 3]))


feat_t_test <- function(df, cluster_var, concept, ts_feature) {
  column_name <- paste0(concept, "_", ts_feature)
  
  group1 <- df[df[[cluster_var]] == unique(df[[cluster_var]])[1], column_name]
  group2 <- df[df[[cluster_var]] == unique(df[[cluster_var]])[2], column_name]
  
  t.test(group1, group2)
}

results <- list()
for (feature in ts_features) {
  for (concept in concepts) {
    results[[feature]][[concept]] <- feat_t_test(raw_feat_clust, "cluster", concept, feature)
  }
}

results_df <- data.frame(concept = character(),
                         feature = character(),
                         difference = numeric(),
                         df = numeric(),
                         t_value = numeric(),
                         p_value = numeric(),
                         lwr = numeric(),
                         upr = numeric(),
                         stringsAsFactors = FALSE)

for (feature in ts_features) {
  for (concept in concepts) {
    # Run t-test
    test_result <- results[[feature]][[concept]]
    
    # Extract required values from t-test result
    difference <- test_result$estimate[1] - test_result$estimate[2]  # difference between group means
    t_value <- test_result$statistic  # t-value
    df <- test_result$parameter  # df
    p_value <- test_result$p.value  # p-value
    lwr <- test_result$conf.int[1] # lower CI
    upr <- test_result$conf.int[2] # upper CI

    # Add a row to the results dataframe
    results_df <- rbind(results_df, data.frame(concept = concept,
                                               feature = feature,
                                               difference = difference,
                                               t_value = t_value,
                                               df = df,
                                               p_value = p_value,
                                               lwr = lwr,
                                               upr = upr,
                                               stringsAsFactors = FALSE))
  }
}

results_df <- results_df %>%
      mutate(
        star = ifelse(p_value < 0.001, "***", ifelse(p_value < 0.01, "**", ifelse(p_value < 0.05, "*", "")))
      ) %>% 
 left_join(
   variableLab,
   by = c('concept' = 'variable')
 )
  

feature_plot_list <- list()
for (feature in unique(results_df$feature)) {
  # Subset the data for the current feature
  feature_data <- results_df[results_df$feature == feature, ]
  
  df_plot <- data.frame(label = feature_data$label,
                        difference = feature_data$difference,
                        lwr = feature_data$lwr,
                        upr = feature_data$upr)
  
  feature_plot_list[[feature]] <- ggplot(df_plot, aes(y = label)) +
    geom_point(aes(x = difference), shape=15, size=2) +
    geom_linerange(aes(xmin = lwr, xmax = upr)) +
    geom_vline(xintercept = 0, linetype="dashed") +
    scale_x_continuous(expand = expansion(mult = 0)) +
    theme_Publication() + 
    theme(panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank(), 
          axis.text.y = element_text(hjust=0), 
          axis.line.y = element_blank(),
          axis.ticks.y = element_blank(),
          axis.title.y = element_blank())
}


# Check if any graphics devices are open
if (length(dev.list()) > 0) {
  # Close the graphics device
  dev.off()
}
pdf("figures/feature_comparison_mad.pdf")
feature_plot_list$mad
dev.off()
png("figures/feature_comparison_mad.png")
feature_plot_list$mad
dev.off()

feat_ttest_apa <- function(results_df, concept_in, feature_in) {
  # concept_in <- "InteractionContextvoluntary"
  # feature_in  <- "median"
  
  diff <- results_df %>% 
    filter(concept == concept_in, feature == feature_in) %>% 
    select(difference) %>% 
    pull %>% 
    round(., 2) %>% 
    format(., nsmall=2)
  t <- results_df %>% 
    filter(concept == concept_in, feature == feature_in) %>% 
    select(t_value) %>% 
    pull %>% 
    round(., 2) %>% 
    format(., nsmall=2)
  df <- results_df %>% 
    filter(concept == concept_in, feature == feature_in) %>% 
    select(df) %>% 
    pull %>% 
    round(., 2) %>%
    format(., nsmall=2)
  p <- results_df %>% 
    filter(concept == concept_in, feature == feature_in) %>% 
    select(p_value) %>% 
    pull
  p <- ifelse(p < 0.001, "< .001", 
              paste0("= ", format(round(p, 3), nsmall=3)))
  lwr <- results_df %>% 
    filter(concept == concept_in, feature == feature_in) %>% 
    select(lwr) %>% 
    pull %>% 
    round(., 2) %>%
    format(., nsmall=2)
  upr <- results_df %>% 
    filter(concept == concept_in, feature == feature_in) %>% 
    select(upr) %>% 
    pull %>% 
    round(., 2) %>%
    format(., nsmall=2)
  
  paste("\\textit{difference} = ", diff,
        ", $t$(", df, ") = ", t,
        ", $p$ ", p , 
        ", \\textit{95\\%CI} [", lwr,
        ", ", upr, "]",
        sep = "")
}
```


Finally, we can also assess the clusters across other individual difference variables \citep[e.g.,][]{monden2022}. This out-of-feature comparison allows us to check for data artifacts, as well as check whether the developmental clusters are associated with important social markers and individual differences. To illustrate artifact checks, we added the number of ESM measurements into the comparison and find that the participants in the deterioration cluster (cluster 2) on average completed slightly more ESM surveys in general and reported on more intergroup interactions in particular (see $n$ in \fgrref[B]{fig:clusterFeatVar}). In our data exclusion procedures, we ensured that the general time frame and completion rates are similar for all participants and indeed the numbers in ESM measurements generally are largely similar (e.g., see $n$ for well-being and outgroup attitudes). However, the difference in the reported number of interactions might indicate either a clustering artifact or a meaningful difference. The higher average number of interactions in cluster 2 could, for example, indicate a clustering artifact if variances are substantially larger due to the larger samples \citep[e.g., restriction of range in the smaller sample][]{kogan2006}. In our case, this seems less likely because one out of four variables did not differ in terms of the MAD (i.e., our selected measurement of the time series variance; see \fgrref{fig:cluster_comparison_mad} for an illustration). At the same time, however, the difference in the number of experienced interactions might also indicate a meaningful difference, where the deteriorating cluster (cluster 2) on average reported more outgroup interactions (`r feat_ttest_apa(results_df, "InteractionContextvoluntary", "n")`), but these interactions were less voluntary (`r feat_ttest_apa(results_df, "InteractionContextvoluntary", "median")`), less meaningful (`r feat_ttest_apa(results_df, "qualityMeaning", "median")`), and less positive (`r feat_ttest_apa(results_df, "qualityOverall", "median")`). Thus, while more research is needed for a conclusive test, our data seems to suggest that the differences in reported interactions are a meaningful difference between the clusters. Such a finding would also be in line with past research highlighting the role of negative intergroup interactions in explaining intergroup relations \citep[e.g.,][]{Barlow2012, Prati2021, Graf2014}. 

```{=tex}
\begin{figure}[!ht] %hbtp
  \caption{Cluster comparison of Median Absolute Deviation for all variables}
  \label{fig:cluster_comparison_mad}
  \centering\includegraphics[width=\textwidth]{figures/feature_comparison_mad.pdf}
\end{figure}
```

To further illustrate the utility of assessing out-of-feature individual differences, we also compare the two samples in terms of the participants' self-reported discrimination experiences in the Netherlands (measured during the post-measurement). When looking at the group comparison, we find that participants in the deteriorating cluster (cluster 2) reported substantially higher levels of everyday discrimination (`r feat_ttest_apa(results_df, "exWB", "EvDayDiscr.post.z")`; \fgrref[B]{fig:clusterFeatVar}). Thus, both intensive longitudinal (e.g., the sum of specific ESM measurements) and cross-sectional variables (e.g., general discrimination differences) that were not included in the original clustering step can be used to explore and understand the cluster differences in more detail.

This cluster separation, then, has a number of empirical and practical applications. Firstly, the clusters are descriptive. With tens of variables, hundreds of participants, and thousands of measurements, singular descriptive statistics are often not able to capture the complex patterns that describe the data set. The feature-based clustering offers some direct insight into the complexity within the data set. In our empirical example, we, for example, see that participants are meaningfully distinguished by a combination of high (vs. low) central tendency, variability, and linear trend. Secondly, the clusters identify important groups. The adaptive and deteriorating groups offer starting points for empirical exploration as well as practical interventions. Researchers can start probing what exactly distinguishes the two groups further and generate new bottom-up hypotheses. Practitioners in the resettlement field can use the group separation to identify individuals in need of assistance and can explore contextual factors that might contribute to the difficulties some might face. In our illustration we, for example, found that participants in the deteriorating cluster (cluster 2) reported less need fulfilling interactions over time. Thirdly, the feature-based approach is flexible and meaningful. We were able to use a wide range of time series features that have been central in the ESM literature and were able to use them directly to identify meaningful groups. For our empirical illustration we, among others for example, chose to focus on whether participants differed in their average well-being (i.e., \textit{median}), how much their well-being would vary over time (i.e, \textit{MAD}), and whether their well-being would on average increase or decrease over time (i.e., \textit{linear trend}). Alternatively, for others cyclical patterns might be more important --- for example, whether well-being was higher on weekends. Importantly, in any case, we did not need to translate these dynamic features into probabilistic inference models (e.g., VAR models) to cluster the participants.

```{=tex}
\begin{figure}[!ht] %hbtp
  \caption{Cluster Group Comparisons over time}
  \label{fig:clusterTs}
  \centering\includegraphics[width=\textwidth]{figures/clusterTsComb.pdf}
  \caption*{Note: \\
  Subplot (A) displays the variable cluster means at every measurement occasion. Subplot (B) shows the GAM spline for each cluster across the measurement occasions. The thinner lines present all individual time series.}
\end{figure}
```



```{r}
#| label: clusterVariableGrid

clusterVariableGrid <- featCluster %>% 
  filter(feature != "n") %>%
  ggplot(., aes(x = feature, y = mean, group = cluster, color = as.factor(cluster))) +
  geom_point() +
  geom_line() +
  scale_colour_manual(values = c("#384B6B", "#E2892B")) + 
  #geom_errorbar(aes(ymin = mean-se, ymax = mean+se), width=.1, position=position_dodge(0.1), size=0.5, alpha=0.4) +
  coord_flip() +
  labs(
    x = "Features",
    y = "Standardized Mean",
    color = "Cluster"
  ) +
  facet_wrap(~ label) +
  theme_Publication()
clusterVariableGrid
```

```{r}
#| label: clusterFeatureGrid

clusterFeatureGrid <- featClusterVal %>% 
  ggplot(., aes(x = label, y = mean, group = cluster, color = as.factor(cluster))) +
  geom_point() +
  geom_line() +
  #geom_ribbon(aes(ymin = mean-se, ymax = mean+se), alpha = 0.2) +
  #geom_errorbar(aes(ymin = mean-se, ymax = mean+se), width=.1, position=position_dodge(0.1), size=0.5, alpha=0.4) +
  scale_colour_manual(values = c("#384B6B", "#E2892B")) + 
  coord_flip() +
  labs(
    x = "Variable",
    y = "Standardized Mean",
    color = "Cluster"
  ) +
  facet_wrap(~ factor(feature, levels = unique(featClusterVal$feature)), ncol=4) +
  theme_Publication()
clusterFeatureGrid
```

```{r}
#| label: clusterFeatVarComb

clusterFeatVarComb <- ggpubr::ggarrange(
  clusterVariableGrid + theme(axis.title.x = element_blank()),
  clusterFeatureGrid,
  ncol = 1,
  labels = c("(A) Variable Focus", "(B) Feature Focus"),
  common.legend = TRUE,
  legend = "bottom",
  align = "v"
) 
ggsave("Figures/clusterFeatVarComb.pdf", clusterFeatVarComb, width = 12, height = 12)
```

```{r clusterTS, include=FALSE}
clusterTS <- rawCluster %>% 
  ggplot(., aes(x=TIDnum, y=value, group=cluster, color=as.factor(cluster))) +
  geom_line(aes(x=TIDnum, y=value, group=ID, color=as.factor(cluster)), alpha=0.05) +
  stat_summary(fun=mean, geom="line") +
  scale_colour_manual(values = c("#384B6B", "#E2892B")) + 
  facet_wrap(~ label, scales = "free_y") +
  labs(
    x = "Time ID",
    y = "Response (Mean Cluster Response Bold)",
    color = "Cluster"
  ) +
  theme_Publication() 
clusterTS
```

```{r clusterTSTrend, include=FALSE}
clusterTSTrend <- rawCluster %>% 
  ggplot(., aes(x=TIDnum, y=value, group=cluster, color=as.factor(cluster))) +
  geom_line(aes(x=TIDnum, y=value, group=ID, color=as.factor(cluster)), alpha=0.05) +
  geom_smooth(aes(group=cluster)) +
  scale_colour_manual(values = c("#384B6B", "#E2892B")) + 
  #stat_summary(fun=mean, geom="line") +
  facet_wrap(~ label, scales = "free_y") +
  labs(
    x = "Time ID",
    y = "Response (Mean Cluster Response Bold)",
    color = "Cluster"
  ) +
  theme_Publication()
clusterTSTrend
```

```{r clusterTsComb, include=FALSE}
clusterTsComb <- ggpubr::ggarrange(
  clusterTS + theme(axis.title.x = element_blank()),
  clusterTSTrend,
  ncol = 1,
  labels = c("(A) Timepoint Means", "(B) Average Spline Trends"),
  common.legend = TRUE,
  legend = "bottom"
)
ggsave("Figures/clusterTsComb.pdf", clusterTsComb, width = 12, height = 12)
```