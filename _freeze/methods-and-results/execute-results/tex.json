{
  "hash": "9cdf8708701fd930e73bc32beebae4af",
  "result": {
    "markdown": "---\noutput: latex_fragment\n# format: \n#   latex:\n#     standalone: false\n#format: context\nbibliography: referencesZotero.bib\ncsl: apa.csl\nexecute:\n  include: false\n  #echo: false\n  #eval: false\n  warning: false\n  error: false\n  #cache: true\n  freeze: auto\n---\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\subsection{Data}\n\nWe used a data set following migration experiences collected by \\citet[][]{Kreienkamp2022b}. The data set consists of three studies that followed migrants who had recently arrived in the Netherlands in their daily interactions with the Dutch majority group members. After a general migration-focused pre-questionnaire, participants were invited twice per day to report on their (potential) interactions with majority group members for at least 30 days. The short ESM surveys were sent out at around lunch (12pm) and dinner time (7pm). After the 30 day study period participants filled in a post-questionnaire that mirrored the pre-questionnaire. Participants received either monetary compensation or partial course credits based on the number of surveys they completed. For our empirical example we focus on the variables that were collected during the ESM surveys and were available in all three studies. Full methodological details are available in \\citet[][]{Kreienkamp2022b}.\n\n\\subsubsection{Sample}\n\nThe original studies included 207 participants ($N_{S1}=$ 23, $N_{S2}=$ 113, $N_{S3}=$ 71) with a total of 10,297 measurements. The studies differed substantially in the maximum length of participation ($\\text{max}(t_{S1})=$ 63, $\\text{max}(t_{S2})=$ 69, $\\text{max}(t_{S3})=$ 155). This was likely due to the option to continue participation without compensation in the later two studies. To make the three studies comparable in participation and time frames, we iteratively removed all measurement occasions and participants that had more than 45% missingness \\citep[which was in line with the general rcecommendation for data that might still need to rely on imputations for later model testing][]{Madley-Dowd2019}. This procedure let to a final sample of 157 participants, who jointly produced 8,132 measurements. Importantly, both the participant repsonse-patterns and the time frame were now a lot more comparable ($\\text{max}(t_{S1})=$ 61, $\\text{max}(t_{S2})=$ 60, $\\text{max}(t_{S3})=$ 67). For a full overview of the data reduction procedure and study-specific exclusions see Online Supplemental Material A.\n\n\\subsubsection{Variables}\n\nWe included 12 variables that were available across all three studies and captured information about the participant's interactions, as well as cognitive-, emotional-, and motivational self in relationship with the majority group. We chose these two aspects in particular because (1) the interaction-specific information exemplified the structural missingness issue of modern ESM data and (2) the motivational, emotional, and cognitive experience offered a diverse conceptualization of migration experience (beyond behavioral measurements) that is becoming more common in the literature \\citep[][]{Kreienkamp2022d}. Full methodological details are available in Online Supplemental Material A, but basic item information, descriptives, and correlations are also available in \\tblref{tab:descrLong}.\n\n\n\n\n\n\n\n\\input{tables/descrLong}\n\n\\subsection{Analysis and Results}\n\nTo perform the main analysis on our selected variables, we showcase the extract--reduce--cluster--evaluate steps in sequential order. For each of the steps fully reproducible and annotated code is available in Online Supplemental A as well as in the accompanying OSF- and GitHub repositories (REF).\n\n\\subsubsection{Feature extraction}\n\n\n\n\n\nFor the features, we selected and extracted one of each of the features proposed in \\tblref{tab:esmFeatures}. We particularly chose the more robust median and median absolute deviation (MAD) for central tendency and variability. Within the variability structure, we chose the slightly more intuitive mean absolute change (MAC) for stability and stayed with the common lag--1 autocorrelation for inertia. For the trend summaries, we chose the overall linear regression slope to describe the linear trend and we summarized the nonlinear trend with the estimated degrees of freedom of an empty GAM spline model (edf) --- the edf summarizes the \\textit{wiggliness} of the spline trend line. We chose these features in particular because we consider them to be the most broadly applicable features. We also extracted the participant's number of completed ESM measurements to ensure that the clusters are comparable in that regard. We provide an R-function that automatically extracts and prepares a large selection of the time series feature operationalizations presented in \\tblref{tab:esmFeatures} in our GitHub repository (see the \\texttt{featureExtractor} function).\n\nFor the central tendency: \\textit{median} ($M$) where $X_{ij}$ is the an ordered list of values from the time series of variable $j$ for participant $i$. The calculation depends on whether the number of measurements in a time series $n$ is odd or even.\n\n\n```{=tex}\n\\begin{equation} \\label{eq:median}\n  M(X_{ij}) = \n    \\begin{cases}\n      X \\left[ \\frac{n+1}{2} \\right] & \\text{if $n$ is odd} \\\\\n      \\frac{X \\left[ \\frac{n}{2} \\right] + X \\left[ \\frac{n}{2} +1 \\right]}{2} & \\text{if $n$ is even}\n    \\end{cases}\n\\end{equation}\n```\n\nFor distribution we chose the \\textit{Median Absolute Deviation} ($MAD$), where we calculate the \\textit{median} ($M$; calculated as in \\eqref{eq:median}) for the absolute deviations of measurement $x$ at time point $t$ for participant $i$ and variable $j$ from the median of that time series $X$.\n\n\n```{=tex}\n\\begin{equation} \\label{eq:mad}\n  MAD(X_{ij}) = M(\\left| x_{ijt} - M(X_{ij})} \\right|)\n\\end{equation}\n```\n\nmean absolute change (MAC) for stability\n\n\n```{=tex}\n\\begin{equation} \\label{eq:mac}\n  MAC(X_{ij}) = \\frac{1}{n-1} \\sum_{t=1, \\ldots, t-1}\\left|x_{t+1}-x_t\\right|\n\\end{equation}\n```\n\nlag--1 autocorrelation for inertia: lag $l=1$\n\n\n```{=tex}\n\\begin{equation} \\label{eq:ar}\n  r_{ij,1} = \\frac{\\sum_{t=1}^{n-l}(x_{ijt}-\\overline{x}_{ij})(x_{ijt-l}-\\overline{x}_{ij})}{\\sum_{t=1}^{n}(x_{ijt}-\\overline{x}_{ij})^2}\n\\end{equation}\n```\n\noverall linear regression slope to describe the linear trend\n\n\n```{=tex}\n\\begin{equation} \\label{eq:lin}\n  b_{ij} = \\frac{\\sum(t-\\overline{t})(x_{ijt}-\\overline{x}_{ij})}{\\sum(t-\\overline{t})^2}\n\\end{equation}\n```\n\nsummarized the nonlinear trend with the estimated degrees of freedom of an empty GAM spline model (edf) --- the edf summarizes the \\textit{wiggliness} of the spline trend line. We estimate the number of parametric and non-parametric (or smooth) terms $p$ in the model.\n\n\n```{=tex}\n\\begin{equation} \\label{eq:edf}\n  edf \\approx \\sum p\n\\end{equation}\n```\n\n\\textit{Notes}: In a Generalized Additive Model (GAM), the estimated degrees of freedom refers to the number of parameters used to estimate the model. This includes the number of parameters used to estimate each smooth function in the model, as well as any additional parameters used for the overall model.On the other hand, the effective degrees of freedom is a measure of the amount of information in the data that is used to estimate the model. It takes into account the smoothness of the estimated functions in the model, and is typically smaller than the estimated degrees of freedom. Effective degrees of freedom is used to estimate the uncertainty of the model estimates and to calculate the model's goodness of fit. In general, the effective degrees of freedom is a more appropriate measure of the complexity of the model than the estimated degrees of freedom, as it accounts for the smoothness of the estimated functions, which can help to prevent overfitting. This is because if the estimated function is smooth, it means that the model is not fitting the noise and has a better generalization.\n\nAfter the feature extraction, we found that about 1.40% of the extracted features are missing across the 72 features per participant. This might, for example, happen if participants do not have two subsequent measurements with outgroup interactions, so that an autocorrelation with lag-1 cannot be calculated for the contact-specific variables. The small number of missing values indicates that the feature-based approach indeed largely avoids the structural missingness issue. The few missing values can, however, be an issue for some feature reduction or feature clustering algorithms. We, thus, impute the missing feature values with a single predictive mean matching imputation using the MICE library.\n\n\\subsubsection{Feature reduction}\n\n\n\n\n\nFor the feature reduction, we chose the common \\textit{principal component analysis} (PCA). Some of the more tailor-made feature selection algorithms can be more accurate in reducing the feature dimensionality and might retain feature importance information more directly, depending on the specific data structure. However, PCAs have the distinct benefit that they are well-established within the psychometric literature and can broadly be applied to a wide variety of studies in an automatize manner. As our aim is to present a general illustration that can also be adopted for more general data descriptive uses, we present the workflow using a PCA here but we encourage users to consider more specialized methods as well.\n\nTo use the principal component analysis with our extracted time series features, we first standardize all features across participants to ensure that all features are weighted equally. We then enter all 72 features into the analysis. The PCA will use linear transformations in such a way that the first component captures the most possible variance of the original data (e.g., by finding a vector that maximizes the sum of squared distances). The following components will then use the same method to iteratively explain the most of the remaining variance while also ensuring that the components are linearly uncorrelated. In practice, this meant that the PCA decomposed the 72 features into 72 principal components but now (because of the uncorrelated linear transformations) the first few principal components will capture a majority of the variance. We can then decide how much information (i.e., variance) we are willing to sacrifice for a reduced dimensionality. A common rule of thumb is to use the principal components that jointly explain 70--90% of the original variance (i.e., cumulative percentage explained variance). For our illustration we select the first 27 principal components that explain 80% of the variance in the original 72 features (reducing the dimensionality by 62.50%). For the extracted principal components we save the 27 PC-scores for each participant (i.e., the participants' coordinates in the reduced dimensional space).\n\nWe would like to comment on two practical matters when using principal components --- the amount of dimensionality reduction and the interpretation of the principal components. As for the expected dimensionality reduction, given its methodology, PCAs tend to 'work better' at reducing dimensions with (highly) correlated variables. Thus, with a set of very homogeneous variables and features users will need less principal components to explain a large amount of variance, while a more diverse set of variables and features will tend to require more principal components to capture the same amount of variance. Our 27 principal components are still a relatively high number of variables but this is not surprising as we chose a diverse conceptualization and a diverse set of time series features. As for the interpretability, PCA allows users to extract information on the meaning of the principal components. In particular, because the principal components are linear combination of original features, users can extract the relative importance of each feature for the extracted principal components (i.e., the eigenvectors). While this can be useful in understanding the variance in the original data or help with manual feature selection, we use the PCA purely to reduce the dimensionality for the clustering step. Instead of relying on the principal components, we use the original features of interest to interpret the later extracted clusters. We particularly advocate for such an approach if the original features were chosen for their psychological meaning in understanding the time series and broader phenomenon of interest.\n\n\\subsubsection{Feature clustering}\n\n\n\n\n\n\n\n\n\n<!-- \\Question{\\textcolor{cyan}{It is good practice to standardize the input of the k-means algorithm. However, I think that does not make sense for PCs because the PCA is based on the idea of decomposing variances (and capturing the most variance in PC1, ...). If I actually standardize the PC-score, we get really weird k-means results. The only discussion of this I could find was a tutorial that DID NOT standardize the PCs: \\url{https://medium.com/more-python-less-problems/principal-component-analysis-and-k-means-clustering-to-visualize-a-high-dimensional-dataset-577b2a7a5fe2}  -->\n\n<!-- I had originally written:  -->\n\n<!-- \"To ensure that the clustering is weighing the principal components equally (as opposed to their variance), we standardize the particpants' PC-scores.\"  -->\n\n<!-- but I went back to the 'raw' PC-scores now. But we should discuss this.}} -->\n\nFor our illustration of the feature clustering procedure, we use the generalizable and efficient centroid-based k-means clustering. The procedure needs the user to make a selection on the optimal number of clusters in order to run the main algorithm. We use the Elbow and the Silhouette method, which both suggest two clusters to be the optimal solution (see Supplemental Material A). We then entered the participants' PC-scores into the k-means algorithm. We used the recommended Hartigan and Wong algorithm \\citep{hartigan1979} with 100 random initial centroid positions to avoid convergence to a sub-optimal solution (i.e., local minima). The k-means analysis assigned 80 participants to cluster 1 and 76 participants to cluster 2.\n\nIn order to interpret the two clusters, we compare the two clusters in their features as well as in their raw time series. We first inspect the clusters with a focus on the included variables (see \\fgrref[A]{fig:clusterFeatVar}). We (1) see that for some variables the features are generally stronger in separating the clusters (e.g., 'how cooperative an interaction was' compared to 'attitudes towards the Dutch'). Additionally, we see that (2) within the variables some features are better at distinguishing clusters (e.g., median of well-being vs. MAC of well-being).We then inspect the clusters with a focus on the features (see \\fgrref[B]{fig:clusterFeatVar}). While this is the same data as for the variable focus, we can see more clearly that some features are better at distinguishing the clusters across variables (e.g., mean and median compared to auto correlations). This offers some information on which features were are most important in understanding the two extracted groups.\n\n\n```{=tex}\n\\begin{figure}[!ht] %hbtp\n  \\caption{Cluster Group Comparisons based on Features and Variables}\n  \\label{fig:clusterFeatVar}\n  \\centering\\includegraphics[width=\\textwidth]{figures/clusterFeatVarComb.pdf}\n  \\caption*{Note: \\\\\n  Within the \"(B) Feature Focus\" subplot, the 'n' and 'Discrimination' comparison variables were not part of the original time series clustering.}\n\\end{figure}\n```\n\nWe can then combine the two focus approaches to assess the developments between the two groups more holistically (see \\fgrref{fig:clusterTs}). Immediately striking are the mean differences, where participants in the second cluster had more meaningful and fulfilling outgroup interactions also consistently reported more voluntary and cooperative interactions but less accidental and involuntary interactions. The same cluster also reported an increase in need fulfilling interaction over the 30 day period and an increase in interactions that were representative of the outgroup. Whereas the other cluster showed a decrease in voluntary, cooperative, and positive interactions over the 30 days. This 'deterioration' cluster also saw a decrease in general need fulfillment and experienced well-being over the 30 days (see \\fgrref[B]{fig:clusterTs}). We also see that while interaction representativeness, outgroup attitudes, well-being are relatively stable for both clusters, the deteriorating cluster also showed substantially higher variablity and instability over time (also see \\fgrref[A]{fig:clusterTs}).\n\n<!-- \\Question{\\textcolor{cyan}{Talk about early warning signals here? E.g., divergences in means over time could be invesitigated with targeted studies.}} -->\n\nWe can also assess the clusters across any other person-level variable. This out-of-feature comparison allows us to check for data artifacts, as well as check whether the developmental clusters are associated with important social markers and individual differences. To illustrate artifact checks, we added the number of measurements into the comparison and find that the participants in the detereoration cluster on average completed more ESM surveys and reported on more intergroup interactions than the cluster with the more positive interactions (see \\fgrref[B]{fig:clusterTs}). While this difference could indicate that the clusters might not entirely be comparable in the response patterns, we can find some relief in our data exclusion procedures during which we ensured that the general time frame and completion rates were not too dissimilar. To illustrate the utility of individual differences, we compare the two samples in terms of the participants' self-reported discrimination experiences in the Netherlands (measured during the post-measurement). \\fgrref[B]{fig:clusterTs} illustrates that participants in the deteriorating cluster reported substantially higher levels of everyday discrimination. Thus, both intensive longitudinal and cross-sectional variables that were not included in the original clustering step can be used to explore and understand the cluster differences in more detail.\n\n\n```{=tex}\n\\begin{figure}[!ht] %hbtp\n  \\caption{Cluster Group Comparisons over time}\n  \\label{fig:clusterTs}\n  \\centering\\includegraphics[width=\\textwidth]{figures/clusterTsComb.pdf}\n  \\caption*{Note: \\\\\n  Subplot (A) displays the variable cluster means at every measurement occasion. Subplot (B) shows the GAM spline for each cluster across the measurement occasions.}\n\\end{figure}\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "\\usepackage{booktabs}\n\\usepackage{longtable}\n\\usepackage{array}\n\\usepackage{multirow}\n\\usepackage{wrapfig}\n\\usepackage{float}\n\\usepackage{colortbl}\n\\usepackage{pdflscape}\n\\usepackage{tabu}\n\\usepackage{threeparttable}\n\\usepackage{threeparttablex}\n\\usepackage[normalem]{ulem}\n\\usepackage{makecell}\n\\usepackage{xcolor}\n"
      ]
    },
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}